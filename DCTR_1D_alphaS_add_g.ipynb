{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the alternative DCTR fitting method applied on Lund jet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import keras\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Lambda, Dense, Input, Layer, Dropout, Dot, Flatten\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 7)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    800         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 57,130\n",
      "Trainable params: 57,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes = (100,100, 128)\n",
    "F_sizes = (100,100, 100)\n",
    "\n",
    "dctr = PFN(input_dim=7, \n",
    "           Phi_sizes=Phi_sizes, F_sizes=F_sizes,\n",
    "           summary=True)\n",
    "\n",
    "#load model from saved file\n",
    "dctr.model.load_weights('./saved_models/DCTR_ee_dijets_1D_alphaS_modified.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_0 = np.load('test1D_default.npz')\n",
    "test_dataset_1 = np.load('test1D_alphaS.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<energyflow.archs.efn.PFN at 0x7f9071e7b8d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6343225641796461806\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913290650\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4010356302392365374\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_default = preprocess_data(test_dataset_0['jet'][:,:,:4])\n",
    "X_unknown = preprocess_data(test_dataset_1['jet'][:,:,:4])\n",
    "\n",
    "Y_default = np.zeros_like(X_unknown[:,0,0])\n",
    "Y_unknown = np.ones_like(X_unknown[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = np.concatenate((X_default, X_unknown), axis = 0)\n",
    "\n",
    "Y_fit = np.concatenate((Y_default, Y_unknown), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = data_split(X_fit, Y_fit, test=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_test = 300000\n",
    "X_train = X_train[:num_data_test,:,:]\n",
    "X_test = X_test[:int(num_data_test/5),:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[:num_data_test]\n",
    "Y_test = Y_test[:int(num_data_test/5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_aLund_value = 0.680\n",
    "fixed_probStuUD_value = 0.217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(d): #from NN (DCTR)\n",
    "    f = dctr.model(d) # Use dctr.model.predict_on_batch(d) when using outside training\n",
    "    weights = (f[:,1])/(f[:,0])\n",
    "    weights = K.expand_dims(weights, axis = 1)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 204)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               26240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 42,881\n",
      "Trainable params: 42,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myinputs = Input(shape=(204,))\n",
    "\n",
    "x = Dense(128, activation='relu')(myinputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=myinputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def my_loss_wrapper(myinputs, theta):\n",
    "    \n",
    "    val = theta\n",
    "    \n",
    "    x = tf.gather(myinputs, np.arange(batch_size))\n",
    "    x = tf.reshape(myinputs, [batch_size,51,4])\n",
    "    \n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    #Creating theta_prime\n",
    "    alphaS = K.ones(shape =x.shape[0:2])*val # Fitting parameter\n",
    "    aLund = K.ones(shape =x.shape[0:2])*fixed_aLund_value # Fixed at default\n",
    "    probStoUD = K.ones(shape =x.shape[0:2])*fixed_probStuUD_value # Fixed at default\n",
    "    theta_prime = K.stack((alphaS, aLund, probStoUD), axis = 2)\n",
    "\n",
    "\n",
    "    data = K.concatenate((x, theta_prime), axis =2)\n",
    "    # print(data.shape) # = (batch_size, 51, 7), correct format to pass to DCTR\n",
    "    weight = reweight(data) # NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        print(\"y_true shape\", y_true.shape)\n",
    "        print(\"y_pred shape\", y_pred.shape)\n",
    "        t_loss = y_true*(y_true - y_pred)**2+(weight)*(1.-y_true)*(y_true - y_pred)**2\n",
    "        return K.mean(t_loss)\n",
    "    \n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = : 0.1\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2315 - acc: 0.5637 - val_loss: 0.2275 - val_acc: 0.5705\n",
      "theta = : 0.10250000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: 0.2272 - acc: 0.5694 - val_loss: 0.2261 - val_acc: 0.5702\n",
      "theta = : 0.10500000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: 0.2255 - acc: 0.5725 - val_loss: 0.2250 - val_acc: 0.5732\n",
      "theta = : 0.1075\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: 0.2242 - acc: 0.5755 - val_loss: 0.2247 - val_acc: 0.5735\n",
      "theta = : 0.11\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2238 - acc: 0.5776 - val_loss: 0.2248 - val_acc: 0.5750\n",
      "theta = : 0.1125\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2245 - acc: 0.5801 - val_loss: 0.2263 - val_acc: 0.5762\n",
      "theta = : 0.115\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2252 - acc: 0.5818 - val_loss: 0.2275 - val_acc: 0.5756\n",
      "theta = : 0.11750000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2260 - acc: 0.5833 - val_loss: 0.2290 - val_acc: 0.5750\n",
      "theta = : 0.12\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2266 - acc: 0.5850 - val_loss: 0.2302 - val_acc: 0.5756\n",
      "theta = : 0.1225\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2272 - acc: 0.5868 - val_loss: 0.2316 - val_acc: 0.5760\n",
      "theta = : 0.125\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2281 - acc: 0.5885 - val_loss: 0.2337 - val_acc: 0.5732\n",
      "theta = : 0.1275\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2291 - acc: 0.5910 - val_loss: 0.2348 - val_acc: 0.5737\n",
      "theta = : 0.13\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2303 - acc: 0.5923 - val_loss: 0.2368 - val_acc: 0.5743\n",
      "theta = : 0.1325\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2312 - acc: 0.5947 - val_loss: 0.2386 - val_acc: 0.5749\n",
      "theta = : 0.135\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2320 - acc: 0.5967 - val_loss: 0.2403 - val_acc: 0.5725\n",
      "theta = : 0.1375\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2326 - acc: 0.5985 - val_loss: 0.2417 - val_acc: 0.5719\n",
      "theta = : 0.14\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2338 - acc: 0.6004 - val_loss: 0.2442 - val_acc: 0.5670\n",
      "theta = : 0.14250000000000002\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2356 - acc: 0.6023 - val_loss: 0.2471 - val_acc: 0.5679\n",
      "theta = : 0.145\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2373 - acc: 0.6041 - val_loss: 0.2499 - val_acc: 0.5624\n",
      "theta = : 0.1475\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2383 - acc: 0.6039 - val_loss: 0.2522 - val_acc: 0.5586\n",
      "theta = : 0.15\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2384 - acc: 0.6040 - val_loss: 0.2543 - val_acc: 0.5454\n",
      "theta = : 0.1525\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: 0.2385 - acc: 0.6027 - val_loss: 0.2548 - val_acc: 0.5478\n",
      "theta = : 0.155\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: 0.2389 - acc: 0.5994 - val_loss: 0.2570 - val_acc: 0.5360\n",
      "theta = : 0.1575\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: 0.2397 - acc: 0.5946 - val_loss: 0.2592 - val_acc: 0.5252\n",
      "theta = : 0.16\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2399 - acc: 0.5872 - val_loss: 0.2611 - val_acc: 0.5156\n",
      "theta = : 0.1625\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2393 - acc: 0.5824 - val_loss: 0.2616 - val_acc: 0.5082\n",
      "theta = : 0.16499999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2390 - acc: 0.5760 - val_loss: 0.2643 - val_acc: 0.4971\n",
      "theta = : 0.16749999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 35us/step - loss: 0.2381 - acc: 0.5714 - val_loss: 0.2656 - val_acc: 0.4983\n",
      "theta = : 0.16999999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2366 - acc: 0.5699 - val_loss: 0.2653 - val_acc: 0.4937\n",
      "theta = : 0.1725\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2351 - acc: 0.5668 - val_loss: 0.2663 - val_acc: 0.4819\n",
      "theta = : 0.175\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2335 - acc: 0.5637 - val_loss: 0.2654 - val_acc: 0.4864\n",
      "theta = : 0.1775\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 35us/step - loss: 0.2320 - acc: 0.5616 - val_loss: 0.2661 - val_acc: 0.4791\n",
      "theta = : 0.18\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: 0.2301 - acc: 0.5600 - val_loss: 0.2655 - val_acc: 0.4774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.231479418327411], [0.22716903626918794], [0.225451968361934], [0.22418870776891708], [0.22384822145104408], [0.22447296629349392], [0.22520247116684913], [0.22595146770278612], [0.22658380672335623], [0.22720454985896746], [0.22809096336364745], [0.2291499452292919], [0.23034379770358404], [0.23122485737005868], [0.23195397441585858], [0.232609174400568], [0.23375322932998338], [0.23556016902128854], [0.23730097909768422], [0.23827513322234153], [0.23841890568534532], [0.23846818134188652], [0.23892308736840884], [0.23972174346446992], [0.23994026804963747], [0.2392687937617302], [0.2390320149064064], [0.2380735764404138], [0.23659973417719204], [0.235136828571558], [0.2335444751381874], [0.23197058339913687], [0.23013629804054897]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.10, 0.18, 33)\n",
    "lvals = []\n",
    "\n",
    "for theta in thetas:\n",
    "    print(\"theta = :\", theta)\n",
    "    model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\n",
    "    history = model.fit(X_train.reshape(-1,204), Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test.reshape(-1,204), Y_test),verbose=1)\n",
    "    lvals+=[history.history['loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas,lvals, label = \"lvals\")\n",
    "plt.vlines(0.160, ymin = np.min(lvals), ymax = np.max(lvals), label = 'Truth')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PFN(input_dim=4, \n",
    "            Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "            output_dim = 1, output_act = 'sigmoid',\n",
    "            summary=False)\n",
    "myinputs = model.inputs[0]\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "def my_loss_wrapper(myinputs, theta):\n",
    "    val = theta\n",
    "    x  = myinputs[:,:,:4] #x.shape = (?,?,4)\n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    #Creating theta_prime\n",
    "    alphaS = K.ones(shape =x.shape[0:2])*val # Fitting parameter\n",
    "    aLund = K.ones(shape =x.shape[0:2])*fixed_aLund_value # Fixed at default\n",
    "    probStoUD = K.ones(shape =x.shape[0:2])*fixed_probStuUD_value # Fixed at default\n",
    "    theta_prime = K.stack((alphaS, aLund, probStoUD), axis = 2)\n",
    "\n",
    "\n",
    "    data = K.concatenate((x, theta_prime), axis =2)\n",
    "    weight = reweight(data) \n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        print(\"y_true shape\", y_true.shape)\n",
    "        print(\"y_pred shape\", y_pred.shape)\n",
    "        t_loss = y_true*(y_true - y_pred)**2+(weight)*(1.-y_true)*(y_true - y_pred)**2\n",
    "        return K.mean(t_loss)\n",
    "    \n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = : 0.1\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 12s 41us/step - loss: 0.2293 - acc: 0.5695 - val_loss: 0.2203 - val_acc: 0.5795\n",
      "theta = : 0.10250000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 12s 41us/step - loss: 0.2225 - acc: 0.5751 - val_loss: 0.2195 - val_acc: 0.5808\n",
      "theta = : 0.10500000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 12s 41us/step - loss: 0.2205 - acc: 0.5781 - val_loss: 0.2200 - val_acc: 0.5815\n",
      "theta = : 0.1075\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 12s 41us/step - loss: 0.2201 - acc: 0.5789 - val_loss: 0.2215 - val_acc: 0.5755\n",
      "theta = : 0.11\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 42us/step - loss: 0.2204 - acc: 0.5794 - val_loss: 0.2206 - val_acc: 0.5770\n",
      "theta = : 0.1125\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 42us/step - loss: 0.2218 - acc: 0.5808 - val_loss: 0.2212 - val_acc: 0.5835\n",
      "theta = : 0.115\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 42us/step - loss: 0.2231 - acc: 0.5811 - val_loss: 0.2240 - val_acc: 0.5775\n",
      "theta = : 0.11750000000000001\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 43us/step - loss: 0.2247 - acc: 0.5819 - val_loss: 0.2243 - val_acc: 0.5856\n",
      "theta = : 0.12\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 43us/step - loss: 0.2259 - acc: 0.5824 - val_loss: 0.2253 - val_acc: 0.5847\n",
      "theta = : 0.1225\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 43us/step - loss: 0.2274 - acc: 0.5816 - val_loss: 0.2284 - val_acc: 0.5839\n",
      "theta = : 0.125\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 44us/step - loss: 0.2291 - acc: 0.5819 - val_loss: 0.2285 - val_acc: 0.5839\n",
      "theta = : 0.1275\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 44us/step - loss: 0.2307 - acc: 0.5820 - val_loss: 0.2306 - val_acc: 0.5850\n",
      "theta = : 0.13\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 44us/step - loss: 0.2325 - acc: 0.5829 - val_loss: 0.2321 - val_acc: 0.5847\n",
      "theta = : 0.1325\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 45us/step - loss: 0.2343 - acc: 0.5836 - val_loss: 0.2340 - val_acc: 0.5846\n",
      "theta = : 0.135\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 45us/step - loss: 0.2357 - acc: 0.5838 - val_loss: 0.2362 - val_acc: 0.5834\n",
      "theta = : 0.1375\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 13s 45us/step - loss: 0.2370 - acc: 0.5837 - val_loss: 0.2373 - val_acc: 0.5829\n",
      "theta = : 0.14\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 46us/step - loss: 0.2389 - acc: 0.5831 - val_loss: 0.2406 - val_acc: 0.5760\n",
      "theta = : 0.14250000000000002\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 46us/step - loss: 0.2416 - acc: 0.5841 - val_loss: 0.2423 - val_acc: 0.5814\n",
      "theta = : 0.145\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 46us/step - loss: 0.2443 - acc: 0.5832 - val_loss: 0.2445 - val_acc: 0.5812\n",
      "theta = : 0.1475\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 47us/step - loss: 0.2461 - acc: 0.5821 - val_loss: 0.2465 - val_acc: 0.5787\n",
      "theta = : 0.15\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 47us/step - loss: 0.2469 - acc: 0.5804 - val_loss: 0.2474 - val_acc: 0.5762\n",
      "theta = : 0.1525\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 47us/step - loss: 0.2477 - acc: 0.5777 - val_loss: 0.2488 - val_acc: 0.5598\n",
      "theta = : 0.155\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 48us/step - loss: 0.2490 - acc: 0.5724 - val_loss: 0.2493 - val_acc: 0.5737\n",
      "theta = : 0.1575\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 48us/step - loss: 0.2506 - acc: 0.5573 - val_loss: 0.2513 - val_acc: 0.5183\n",
      "theta = : 0.16\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: 0.2516 - acc: 0.5300 - val_loss: 0.2521 - val_acc: 0.4998\n",
      "theta = : 0.1625\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: 0.2518 - acc: 0.5010 - val_loss: 0.2524 - val_acc: 0.4674\n",
      "theta = : 0.16499999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: 0.2522 - acc: 0.4738 - val_loss: 0.2529 - val_acc: 0.4728\n",
      "theta = : 0.16749999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: 0.2520 - acc: 0.4554 - val_loss: 0.2528 - val_acc: 0.4530\n",
      "theta = : 0.16999999999999998\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: 0.2513 - acc: 0.4530 - val_loss: 0.2521 - val_acc: 0.4478\n",
      "theta = : 0.1725\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: 0.2505 - acc: 0.4459 - val_loss: 0.2516 - val_acc: 0.4412\n",
      "theta = : 0.175\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 50us/step - loss: 0.2495 - acc: 0.4447 - val_loss: 0.2505 - val_acc: 0.4383\n",
      "theta = : 0.1775\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: 0.2485 - acc: 0.4447 - val_loss: 0.2495 - val_acc: 0.4359\n",
      "theta = : 0.18\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: 0.2472 - acc: 0.4466 - val_loss: 0.2487 - val_acc: 0.4323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22930769001444182], [0.22246183335781097], [0.22052572369575502], [0.22006317521135013], [0.220433938652277], [0.22176049257318178], [0.22313122366865476], [0.22466515352328617], [0.2259424437582493], [0.22742291778326035], [0.22905076464017232], [0.23071857139468194], [0.23252388616402944], [0.2342507680753867], [0.23573199356595675], [0.2369984382390976], [0.23894562537471453], [0.24159237399697303], [0.24426528548200926], [0.24605256587266922], [0.24692536811033886], [0.24769828180472056], [0.24897778232892354], [0.2505668371419112], [0.25163893406589827], [0.2517722984155019], [0.25223049089312555], [0.25204878191153207], [0.25127878934144976], [0.25050059959292414], [0.24948631743590036], [0.24845548609892526], [0.24719080274303754]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.10, 0.18, 33)\n",
    "lvals = []\n",
    "\n",
    "for theta in thetas:\n",
    "    print(\"theta = :\", theta)\n",
    "    model.model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1)\n",
    "    lvals+=[history.history['loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(thetas,lvals, label = \"lvals\")\n",
    "plt.vlines(0.160, ymin = np.min(lvals), ymax = np.max(lvals), label = 'Truth')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddParams2Input(keras.layers.Layer):\n",
    "    \"\"\" Custom layer for tuning with DCTR: \n",
    "    Arguments:\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Usage: \n",
    "    Let X_dim be the input dimension of each particle to a PFN model, and n_MC_params be the number of MC parameters. \n",
    "    Defines a Layer that takes in an array of dimension \n",
    "    (batch_size, padded_multiplicity, X_dim - n_MC_params)\n",
    "    This layer appends each particle by the default_MC_params and makes then trainable or non-trainable based on trainable_MC_params\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_MC_params, default_MC_params, trainable_MC_params):\n",
    "        super(AddParams2Input, self).__init__()\n",
    "        # Definitions\n",
    "        self.n_MC_params = n_MC_params\n",
    "        self.MC_params = default_MC_params\n",
    "        self.trainable_MC_params = trainable_MC_params\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Convert input MC parameters to weights and make then trainable or non-trainable\n",
    "        for i in range(self.n_MC_params):\n",
    "            self.MC_params[i] = self.add_weight(name='MC_param_{}'.format(i), \n",
    "                                                shape=(1, 1),\n",
    "                                                initializer=keras.initializers.Constant(self.MC_params[i]),\n",
    "                                                trainable=self.trainable_MC_params[i])\n",
    "            \n",
    "        self.MC_params = keras.backend.tf.concat(self.MC_params, axis = -1)\n",
    "        super(AddParams2Input, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        # Add MC params to each input particle (but not to the padded rows)\n",
    "        concat_input_and_params = keras.backend.tf.where(keras.backend.abs(input[...,0])>0,\n",
    "                                                         self.MC_params*keras.backend.ones_like(input[...,0:self.n_MC_params]),\n",
    "                                                         keras.backend.zeros_like(input[...,0:self.n_MC_params]))\n",
    "        return keras.backend.concatenate([input, concat_input_and_params], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]+self.n_MC_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g,theta) fit for DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 204)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               26240     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 42,881\n",
      "Trainable params: 42,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 204)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               26240     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1)                 1         \n",
      "=================================================================\n",
      "Total params: 42,882\n",
      "Trainable params: 42,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Theta fit value is 0.14\n",
      "Epoch:  0\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 25us/step - loss: 0.2445 - acc: 0.5539 - val_loss: 0.2428 - val_acc: 0.5661\n",
      ". theta fit =  0.14\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: -0.2574 - acc: 0.5653 - val_loss: -0.2652 - val_acc: 0.5661\n",
      ". theta fit =  0.17790197\n",
      "Theta fit value is 0.17790197\n",
      "Epoch:  1\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 7s 25us/step - loss: 0.2535 - acc: 0.5094 - val_loss: 0.2511 - val_acc: 0.4436\n",
      ". theta fit =  0.17790197\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: -0.2523 - acc: 0.4503 - val_loss: -0.2532 - val_acc: 0.4436\n",
      ". theta fit =  0.16665928\n",
      "Theta fit value is 0.16665928\n",
      "Epoch:  2\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 25us/step - loss: 0.2527 - acc: 0.4489 - val_loss: 0.2532 - val_acc: 0.4447\n",
      ". theta fit =  0.16665928\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: -0.2521 - acc: 0.4535 - val_loss: -0.2532 - val_acc: 0.4447\n",
      ". theta fit =  0.16646984\n",
      "Theta fit value is 0.16646984\n",
      "Epoch:  3\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 26us/step - loss: 0.2523 - acc: 0.4511 - val_loss: 0.2531 - val_acc: 0.4448\n",
      ". theta fit =  0.16646984\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: -0.2517 - acc: 0.4543 - val_loss: -0.2531 - val_acc: 0.4448\n",
      ". theta fit =  0.16659921\n",
      "Theta fit value is 0.16659921\n",
      "Epoch:  4\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 26us/step - loss: 0.2520 - acc: 0.4519 - val_loss: 0.2533 - val_acc: 0.4463\n",
      ". theta fit =  0.16659921\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: -0.2514 - acc: 0.4591 - val_loss: -0.2533 - val_acc: 0.4463\n",
      ". theta fit =  0.16665609\n",
      "Theta fit value is 0.16665609\n",
      "Epoch:  5\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 27us/step - loss: 0.2516 - acc: 0.4563 - val_loss: 0.2533 - val_acc: 0.4472\n",
      ". theta fit =  0.16665609\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: -0.2511 - acc: 0.4601 - val_loss: -0.2532 - val_acc: 0.4472\n",
      ". theta fit =  0.16608402\n",
      "Theta fit value is 0.16608402\n",
      "Epoch:  6\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 27us/step - loss: 0.2513 - acc: 0.4602 - val_loss: 0.2534 - val_acc: 0.4511\n",
      ". theta fit =  0.16608402\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: -0.2508 - acc: 0.4666 - val_loss: -0.2534 - val_acc: 0.4511\n",
      ". theta fit =  0.16666295\n",
      "Theta fit value is 0.16666295\n",
      "Epoch:  7\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 27us/step - loss: 0.2510 - acc: 0.4647 - val_loss: 0.2536 - val_acc: 0.4532\n",
      ". theta fit =  0.16666295\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: -0.2504 - acc: 0.4723 - val_loss: -0.2536 - val_acc: 0.4532\n",
      ". theta fit =  0.16588216\n",
      "Theta fit value is 0.16588216\n",
      "Epoch:  8\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 8s 28us/step - loss: 0.2506 - acc: 0.4701 - val_loss: 0.2535 - val_acc: 0.4532\n",
      ". theta fit =  0.16588216\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: -0.2499 - acc: 0.4764 - val_loss: -0.2535 - val_acc: 0.4532\n",
      ". theta fit =  0.16620393\n",
      "Theta fit value is 0.16620393\n",
      "Epoch:  9\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: 0.2502 - acc: 0.4747 - val_loss: 0.2538 - val_acc: 0.4552\n",
      ". theta fit =  0.16620393\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: -0.2495 - acc: 0.4799 - val_loss: -0.2538 - val_acc: 0.4552\n",
      ". theta fit =  0.16616987\n",
      "Theta fit value is 0.16616987\n",
      "Epoch:  10\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 29us/step - loss: 0.2498 - acc: 0.4775 - val_loss: 0.2540 - val_acc: 0.4550\n",
      ". theta fit =  0.16616987\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: -0.2491 - acc: 0.4805 - val_loss: -0.2540 - val_acc: 0.4550\n",
      ". theta fit =  0.16634886\n",
      "Theta fit value is 0.16634886\n",
      "Epoch:  11\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2494 - acc: 0.4807 - val_loss: 0.2541 - val_acc: 0.4586\n",
      ". theta fit =  0.16634886\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: -0.2485 - acc: 0.4899 - val_loss: -0.2540 - val_acc: 0.4586\n",
      ". theta fit =  0.16544914\n",
      "Theta fit value is 0.16544914\n",
      "Epoch:  12\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2491 - acc: 0.4878 - val_loss: 0.2542 - val_acc: 0.4633\n",
      ". theta fit =  0.16544914\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000/300000 [==============================] - 10s 34us/step - loss: -0.2483 - acc: 0.4938 - val_loss: -0.2543 - val_acc: 0.4633\n",
      ". theta fit =  0.1662048\n",
      "Theta fit value is 0.1662048\n",
      "Epoch:  13\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 31us/step - loss: 0.2488 - acc: 0.4894 - val_loss: 0.2545 - val_acc: 0.4602\n",
      ". theta fit =  0.1662048\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: -0.2477 - acc: 0.4953 - val_loss: -0.2545 - val_acc: 0.4602\n",
      ". theta fit =  0.16625358\n",
      "Theta fit value is 0.16625358\n",
      "Epoch:  14\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 9s 30us/step - loss: 0.2483 - acc: 0.4912 - val_loss: 0.2548 - val_acc: 0.4656\n",
      ". theta fit =  0.16625358\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 34us/step - loss: -0.2474 - acc: 0.5026 - val_loss: -0.2548 - val_acc: 0.4656\n",
      ". theta fit =  0.16652063\n",
      "Theta fit value is 0.16652063\n",
      "Epoch:  15\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2480 - acc: 0.4950 - val_loss: 0.2547 - val_acc: 0.4637\n",
      ". theta fit =  0.16652063\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 35us/step - loss: -0.2468 - acc: 0.5009 - val_loss: -0.2547 - val_acc: 0.4637\n",
      ". theta fit =  0.16549303\n",
      "Theta fit value is 0.16549303\n",
      "Epoch:  16\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2475 - acc: 0.4998 - val_loss: 0.2551 - val_acc: 0.4665\n",
      ". theta fit =  0.16549303\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 35us/step - loss: -0.2464 - acc: 0.5071 - val_loss: -0.2552 - val_acc: 0.4665\n",
      ". theta fit =  0.16603805\n",
      "Theta fit value is 0.16603805\n",
      "Epoch:  17\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2470 - acc: 0.5022 - val_loss: 0.2553 - val_acc: 0.4689\n",
      ". theta fit =  0.16603805\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 36us/step - loss: -0.2460 - acc: 0.5097 - val_loss: -0.2553 - val_acc: 0.4689\n",
      ". theta fit =  0.1659925\n",
      "Theta fit value is 0.1659925\n",
      "Epoch:  18\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 32us/step - loss: 0.2467 - acc: 0.5057 - val_loss: 0.2554 - val_acc: 0.4673\n",
      ". theta fit =  0.1659925\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 36us/step - loss: -0.2455 - acc: 0.5099 - val_loss: -0.2555 - val_acc: 0.4673\n",
      ". theta fit =  0.16653083\n",
      "Theta fit value is 0.16653083\n",
      "Epoch:  19\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 10s 33us/step - loss: 0.2462 - acc: 0.5072 - val_loss: 0.2557 - val_acc: 0.4666\n",
      ". theta fit =  0.16653083\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 11s 36us/step - loss: -0.2450 - acc: 0.5096 - val_loss: -0.2555 - val_acc: 0.4666\n",
      ". theta fit =  0.16465488\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LambdaCallback\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(\". theta fit = \",model_fit.layers[-1].get_weights()[-1]))\n",
    "theta_fit_init = 0.14\n",
    "fit_vals = [theta_fit_init]\n",
    "append_fit_value = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(model_fit.layers[-1].get_weights()[0]))\n",
    "\n",
    "callbacks = [print_weights, append_fit_value]\n",
    "\n",
    "myinputs = Input(shape=(204,))\n",
    "x = Dense(128, activation='relu')(myinputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "dnn_model = Model(inputs=myinputs, outputs=predictions)\n",
    "dnn_model.summary()\n",
    "\n",
    "myinputs_fit = dnn_model.inputs[0]\n",
    "identity = Lambda(lambda x: x + 0)(dnn_model.output)\n",
    "\n",
    "model_fit = Model(inputs=myinputs_fit, outputs=identity)\n",
    "model_fit.layers[np.size(model_fit.layers)-1].add_weight(name=\"thetaX\",shape=list(),\n",
    "                                                         initializer = keras.initializers.Constant(value = theta_fit_init),\n",
    "                                                         trainable=True)\n",
    "model_fit.summary()\n",
    "\n",
    "train_theta = False\n",
    "\n",
    "batch_size = int(len(X_train)/50) #larger batch_size leads to better precision (at least for Guassian case)\n",
    "epochs = 20 #but requires more epochs to train\n",
    "\n",
    "\n",
    "def my_loss_wrapper_fit(myinputs, train_theta, mysign = 1):  \n",
    "    #Getting theta0:\n",
    "    if train_theta == False:\n",
    "        theta0 = model_fit.layers[-1].get_weights() #when not training theta, fetch as np array \n",
    "    else:\n",
    "        theta0 = model_fit.trainable_weights[-1] #when training theta, fetch as tf.Variable\n",
    "        \n",
    "    x = tf.gather(myinputs, np.arange(batch_size))\n",
    "    x = tf.reshape(myinputs, [batch_size,51,4])\n",
    "    \n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    #Creating theta_prime\n",
    "    alphaS = K.ones(shape =x.shape[0:2])*theta0 # Fitting parameter\n",
    "    aLund = K.ones(shape =x.shape[0:2])*fixed_aLund_value # Fixed at default\n",
    "    probStoUD = K.ones(shape =x.shape[0:2])*fixed_probStuUD_value # Fixed at default\n",
    "    theta_prime = K.stack((alphaS, aLund, probStoUD), axis = 2)\n",
    "\n",
    "\n",
    "    data = K.concatenate((x, theta_prime), axis =2)\n",
    "    # print(data.shape) # = (batch_size, 51, 7), correct format to pass to DCTR\n",
    "    weight = reweight(data) # NN reweight\n",
    "   \n",
    "    w = reweight(data) #NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean Squared Loss\n",
    "        t_loss = mysign*(y_true*(y_true - y_pred)**2+(w)*(1.-y_true)*(y_true - y_pred)**2)\n",
    "        # Categorical Cross-Entropy Loss\n",
    "        \n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        '''\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -mysign*((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss\n",
    "    \n",
    "for k in range(epochs):  \n",
    "    \n",
    "    theta0 = model_fit.layers[-1].get_weights() \n",
    "    print(\"Theta fit value is\", theta0[0])\n",
    "    \n",
    "    print(\"Epoch: \",k )\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        model_fit.layers[i].trainable = True\n",
    "        pass\n",
    "    train_theta = False\n",
    "    model_fit.layers[-1].trainable = False\n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit, train_theta, 1),\n",
    "                      metrics=['accuracy'])\n",
    "    print(\"Training g\")\n",
    "    \n",
    "    model_fit.fit(X_train.reshape(-1,204), Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test.reshape(-1,204), Y_test),verbose=1,callbacks=callbacks)\n",
    "\n",
    "    \n",
    "    #######################################################################################\n",
    "    #Now, fix g and train \\theta.\n",
    "    \n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        model_fit.layers[i].trainable = False\n",
    "        pass    \n",
    "    train_theta = True\n",
    "    model_fit.layers[-1].trainable = True\n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit, train_theta, -1),\n",
    "                      metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    print(\"Training theta\")\n",
    "    model_fit.fit(X_train.reshape(-1,204), Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test.reshape(-1,204), Y_test),verbose=1,callbacks=callbacks)\n",
    " \n",
    "    pass\n",
    "\n",
    "plt.plot(fit_vals, label='Model Fit')\n",
    "plt.hlines(0.16, 0, len(fit_vals), label = 'Truth')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(r'$\\theta_{fit}$')\n",
    "plt.legend()\n",
    "plt.title(\"fitting plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adi's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PFN(input_dim=4, \n",
    "            Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "            output_dim = 1, output_act = 'sigmoid',\n",
    "            summary=False)\n",
    "myinputs = model.inputs[0]\n",
    "batch_size = 1000\n",
    "\n",
    "def my_loss_wrapper(inputs,val=0):\n",
    "    x  = inputs #x.shape = (?,?,4)\n",
    "    # Reshaping to correct format\n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    #Creating theta_prime\n",
    "    alphaS = K.ones(shape =x.shape[0:2])*val # Fitting parameter\n",
    "    aLund = K.ones(shape =x.shape[0:2])*0.68 # Fixed at default\n",
    "    probStoUD = K.ones(shape =x.shape[0:2])*0.217 # Fixed at default\n",
    "    theta_prime = K.stack((alphaS, aLund, probStoUD), axis = 2)\n",
    "\n",
    "\n",
    "    data = K.concatenate((x, theta_prime), axis =2)\n",
    "    # print(data.shape) # = (batch_size, 51, 7), correct format to pass to DCTR\n",
    "    w = reweight(data) # NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean-Squared Loss:\n",
    "        t_loss = (y_true)*(y_true - y_pred)**2 +(w)*(1-y_true)*(y_true - y_pred)**2\n",
    "        \n",
    "        # Categorical Cross-Entropy Loss\n",
    "        '''\n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        \n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainnig theta = : 0.1\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 18s 60us/step - loss: 0.2300 - acc: 0.5691 - val_loss: 0.2277 - val_acc: 0.5688\n",
      "trainnig theta = : 0.10250000000000001\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 18s 61us/step - loss: 0.2226 - acc: 0.5750 - val_loss: 0.2208 - val_acc: 0.5761\n",
      "trainnig theta = : 0.10500000000000001\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 18s 61us/step - loss: 0.2205 - acc: 0.5777 - val_loss: 0.2189 - val_acc: 0.5824\n",
      "trainnig theta = : 0.1075\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 18s 62us/step - loss: 0.2199 - acc: 0.5792 - val_loss: 0.2180 - val_acc: 0.5824\n",
      "trainnig theta = : 0.11\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 18s 62us/step - loss: 0.2200 - acc: 0.5805 - val_loss: 0.2195 - val_acc: 0.5798\n",
      "trainnig theta = : 0.1125\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 62us/step - loss: 0.2215 - acc: 0.5813 - val_loss: 0.2229 - val_acc: 0.5833\n",
      "trainnig theta = : 0.115\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 63us/step - loss: 0.2231 - acc: 0.5816 - val_loss: 0.2250 - val_acc: 0.5843\n",
      "trainnig theta = : 0.11750000000000001\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 63us/step - loss: 0.2244 - acc: 0.5831 - val_loss: 0.2244 - val_acc: 0.5844\n",
      "trainnig theta = : 0.12\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 64us/step - loss: 0.2258 - acc: 0.5825 - val_loss: 0.2254 - val_acc: 0.5838\n",
      "trainnig theta = : 0.1225\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 64us/step - loss: 0.2272 - acc: 0.5828 - val_loss: 0.2268 - val_acc: 0.5833\n",
      "trainnig theta = : 0.125\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 64us/step - loss: 0.2289 - acc: 0.5831 - val_loss: 0.2286 - val_acc: 0.5836\n",
      "trainnig theta = : 0.1275\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 64us/step - loss: 0.2305 - acc: 0.5836 - val_loss: 0.2305 - val_acc: 0.5841\n",
      "trainnig theta = : 0.13\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 64us/step - loss: 0.2323 - acc: 0.5832 - val_loss: 0.2323 - val_acc: 0.5856\n",
      "trainnig theta = : 0.1325\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 65us/step - loss: 0.2340 - acc: 0.5841 - val_loss: 0.2345 - val_acc: 0.5818\n",
      "trainnig theta = : 0.135\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 19s 65us/step - loss: 0.2355 - acc: 0.5846 - val_loss: 0.2357 - val_acc: 0.5820\n",
      "trainnig theta = : 0.1375\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 65us/step - loss: 0.2368 - acc: 0.5849 - val_loss: 0.2369 - val_acc: 0.5850\n",
      "trainnig theta = : 0.14\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 65us/step - loss: 0.2388 - acc: 0.5850 - val_loss: 0.2394 - val_acc: 0.5833\n",
      "trainnig theta = : 0.14250000000000002\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 66us/step - loss: 0.2415 - acc: 0.5839 - val_loss: 0.2420 - val_acc: 0.5831\n",
      "trainnig theta = : 0.145\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 67us/step - loss: 0.2442 - acc: 0.5827 - val_loss: 0.2450 - val_acc: 0.5749\n",
      "trainnig theta = : 0.1475\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 67us/step - loss: 0.2460 - acc: 0.5825 - val_loss: 0.2465 - val_acc: 0.5829\n",
      "trainnig theta = : 0.15\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 67us/step - loss: 0.2469 - acc: 0.5811 - val_loss: 0.2473 - val_acc: 0.5776\n",
      "trainnig theta = : 0.1525\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 68us/step - loss: 0.2475 - acc: 0.5797 - val_loss: 0.2484 - val_acc: 0.5739\n",
      "trainnig theta = : 0.155\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 68us/step - loss: 0.2488 - acc: 0.5756 - val_loss: 0.2495 - val_acc: 0.5645\n",
      "trainnig theta = : 0.1575\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 20s 68us/step - loss: 0.2504 - acc: 0.5592 - val_loss: 0.2509 - val_acc: 0.5604\n",
      "trainnig theta = : 0.16\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 69us/step - loss: 0.2515 - acc: 0.5290 - val_loss: 0.2523 - val_acc: 0.5233\n",
      "trainnig theta = : 0.1625\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 69us/step - loss: 0.2516 - acc: 0.5086 - val_loss: 0.2526 - val_acc: 0.4931\n",
      "trainnig theta = : 0.16499999999999998\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 69us/step - loss: 0.2520 - acc: 0.4797 - val_loss: 0.2528 - val_acc: 0.4637\n",
      "trainnig theta = : 0.16749999999999998\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 71us/step - loss: 0.2518 - acc: 0.4676 - val_loss: 0.2530 - val_acc: 0.4655\n",
      "trainnig theta = : 0.16999999999999998\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 70us/step - loss: 0.2511 - acc: 0.4606 - val_loss: 0.2522 - val_acc: 0.4451\n",
      "trainnig theta = : 0.1725\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 21s 71us/step - loss: 0.2501 - acc: 0.4566 - val_loss: 0.2517 - val_acc: 0.4528\n",
      "trainnig theta = : 0.175\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 22s 72us/step - loss: 0.2491 - acc: 0.4553 - val_loss: 0.2508 - val_acc: 0.4443\n",
      "trainnig theta = : 0.1775\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 22s 72us/step - loss: 0.2480 - acc: 0.4525 - val_loss: 0.2500 - val_acc: 0.4431\n",
      "trainnig theta = : 0.18\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 22s 73us/step - loss: 0.2468 - acc: 0.4526 - val_loss: 0.2492 - val_acc: 0.4428\n",
      "[[0.229964496443669], [0.22264581948518752], [0.22053895036379495], [0.21989073887467384], [0.22004573459426563], [0.22150545299053193], [0.22306145618359247], [0.22439728076259294], [0.22581284110744795], [0.22721085156003634], [0.22886528154214222], [0.23049915313720704], [0.23225902929902076], [0.2340306996802489], [0.23546812916795412], [0.23676030491789182], [0.23876916070779164], [0.2415154860417048], [0.24420700351397195], [0.24600527212023734], [0.24688482359051706], [0.2475017729898294], [0.24883155316114425], [0.2504448263843854], [0.2515316822131475], [0.25158005207777023], [0.25200686007738116], [0.2517644842962424], [0.2510591562092304], [0.2501390003164609], [0.2491446832815806], [0.2480064043402672], [0.24675335243344307]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.10, 0.18, 33) #iterating across possible alphaS values\n",
    "vlvals = []\n",
    "lvals = []\n",
    "\n",
    "\n",
    "for theta in thetas:\n",
    "    print(\"trainnig theta = :\", theta)\n",
    "    model.model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1)\n",
    "    vlvals+=[history.history['val_loss']]\n",
    "    lvals+=[history.history['loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas,lvals, label = \"lvals\")\n",
    "plt.plot(thetas,vlvals, label = \"vlvals\")\n",
    "plt.vlines(0.160, ymin = np.min(lvals), ymax = np.max(lvals), label = 'Truth')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"MSE for alphaS altFit SUCCESS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LambdaCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(\". theta fit = \",model_fit.layers[-1].get_weights()[-1]))\n",
    "theta_fit_init = 0.12\n",
    "fit_vals = [theta_fit_init]\n",
    "append_fit_value = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(model_fit.layers[-1].get_weights()[0]))\n",
    "\n",
    "callbacks = [print_weights, append_fit_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            101         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1)            0           output[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            1           activation_35[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 56,730\n",
      "Trainable params: 56,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch:  0\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 48us/step - loss: 0.2789 - acc: 0.5294 - val_loss: 0.2389 - val_acc: 0.5629\n",
      ". theta fit =  0.12\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 47us/step - loss: -0.2435 - acc: 0.5636 - val_loss: -0.2490 - val_acc: 0.5629\n",
      ". theta fit =  0.1399992\n",
      "Epoch:  1\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 48us/step - loss: 0.2540 - acc: 0.5486 - val_loss: 0.2443 - val_acc: 0.5582\n",
      ". theta fit =  0.1399992\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 48us/step - loss: -0.2502 - acc: 0.5579 - val_loss: -0.2572 - val_acc: 0.5582\n",
      ". theta fit =  0.15825866\n",
      "Epoch:  2\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 14s 48us/step - loss: 0.2580 - acc: 0.5172 - val_loss: 0.2528 - val_acc: 0.5049\n",
      ". theta fit =  0.15825866\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 50us/step - loss: -0.2535 - acc: 0.5095 - val_loss: -0.2549 - val_acc: 0.5049\n",
      ". theta fit =  0.17021042\n",
      "Epoch:  3\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 50us/step - loss: 0.2606 - acc: 0.4846 - val_loss: 0.2542 - val_acc: 0.4641\n",
      ". theta fit =  0.17021042\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 49us/step - loss: -0.2542 - acc: 0.4680 - val_loss: -0.2548 - val_acc: 0.4641\n",
      ". theta fit =  0.1663187\n",
      "Epoch:  4\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 50us/step - loss: 0.2561 - acc: 0.4912 - val_loss: 0.2541 - val_acc: 0.4713\n",
      ". theta fit =  0.1663187\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 50us/step - loss: -0.2536 - acc: 0.4737 - val_loss: -0.2541 - val_acc: 0.4713\n",
      ". theta fit =  0.1669113\n",
      "Epoch:  5\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: 0.2539 - acc: 0.4633 - val_loss: 0.2533 - val_acc: 0.4388\n",
      ". theta fit =  0.1669113\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: -0.2528 - acc: 0.4416 - val_loss: -0.2533 - val_acc: 0.4388\n",
      ". theta fit =  0.16677518\n",
      "Epoch:  6\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 52us/step - loss: 0.2537 - acc: 0.4554 - val_loss: 0.2532 - val_acc: 0.4422\n",
      ". theta fit =  0.16677518\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 51us/step - loss: -0.2528 - acc: 0.4462 - val_loss: -0.2533 - val_acc: 0.4422\n",
      ". theta fit =  0.16659756\n",
      "Epoch:  7\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 15s 52us/step - loss: 0.2534 - acc: 0.4522 - val_loss: 0.2531 - val_acc: 0.4407\n",
      ". theta fit =  0.16659756\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 52us/step - loss: -0.2526 - acc: 0.4432 - val_loss: -0.2531 - val_acc: 0.4407\n",
      ". theta fit =  0.16574612\n",
      "Epoch:  8\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 52us/step - loss: 0.2535 - acc: 0.4602 - val_loss: 0.2530 - val_acc: 0.4397\n",
      ". theta fit =  0.16574612\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000/300000 [==============================] - 16s 53us/step - loss: -0.2527 - acc: 0.4399 - val_loss: -0.2530 - val_acc: 0.4397\n",
      ". theta fit =  0.1654842\n",
      "Epoch:  9\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 53us/step - loss: 0.2532 - acc: 0.4489 - val_loss: 0.2531 - val_acc: 0.4418\n",
      ". theta fit =  0.1654842\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 53us/step - loss: -0.2527 - acc: 0.4437 - val_loss: -0.2531 - val_acc: 0.4418\n",
      ". theta fit =  0.16681118\n",
      "Epoch:  10\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 53us/step - loss: 0.2529 - acc: 0.4464 - val_loss: 0.2531 - val_acc: 0.4356\n",
      ". theta fit =  0.16681118\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 56us/step - loss: -0.2526 - acc: 0.4376 - val_loss: -0.2531 - val_acc: 0.4356\n",
      ". theta fit =  0.16570228\n",
      "Epoch:  11\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 54us/step - loss: 0.2529 - acc: 0.4452 - val_loss: 0.2531 - val_acc: 0.4433\n",
      ". theta fit =  0.16570228\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 55us/step - loss: -0.2527 - acc: 0.4457 - val_loss: -0.2531 - val_acc: 0.4433\n",
      ". theta fit =  0.1659656\n",
      "Epoch:  12\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 55us/step - loss: 0.2528 - acc: 0.4437 - val_loss: 0.2531 - val_acc: 0.4363\n",
      ". theta fit =  0.1659656\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 16s 54us/step - loss: -0.2525 - acc: 0.4411 - val_loss: -0.2531 - val_acc: 0.4363\n",
      ". theta fit =  0.16649634\n",
      "Epoch:  13\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 57us/step - loss: 0.2529 - acc: 0.4439 - val_loss: 0.2530 - val_acc: 0.4397\n",
      ". theta fit =  0.16649634\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 55us/step - loss: -0.2526 - acc: 0.4410 - val_loss: -0.2530 - val_acc: 0.4397\n",
      ". theta fit =  0.16571018\n",
      "Epoch:  14\n",
      "Training g\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 56us/step - loss: 0.2526 - acc: 0.4421 - val_loss: 0.2530 - val_acc: 0.4353\n",
      ". theta fit =  0.16571018\n",
      "Training theta\n",
      "Train on 300000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 17s 55us/step - loss: -0.2525 - acc: 0.4396 - val_loss: -0.2530 - val_acc: 0.4353\n",
      ". theta fit =  0.16599585\n"
     ]
    }
   ],
   "source": [
    "def reweight(d): #from NN (DCTR)\n",
    "    f = dctr.model(d) # Use dctr.model.predict_on_batch(d) when using outside training\n",
    "    weights = (f[:,1])/(f[:,0])\n",
    "    weights = K.expand_dims(weights, axis = 1)\n",
    "    return weights\n",
    "\n",
    "PFN_model = PFN(input_dim=4, \n",
    "            Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "            output_dim = 1, output_act = 'sigmoid',\n",
    "            summary=False)\n",
    "myinputs_fit = PFN_model.inputs[0]\n",
    "\n",
    "identity = Lambda(lambda x: x + 0)(PFN_model.output)\n",
    "\n",
    "model_fit = Model(inputs=myinputs_fit, outputs=identity)\n",
    "model_fit.layers[np.size(model_fit.layers)-1].add_weight(name=\"thetaX\",shape=list(),\n",
    "                                                         initializer = keras.initializers.Constant(value = theta_fit_init),\n",
    "                                                         trainable=True)\n",
    "model_fit.summary()\n",
    "\n",
    "train_theta = False\n",
    "\n",
    "batch_size = int(len(X_train)/20) #larger batch_size leads to better precision (at least for Guassian case)\n",
    "epochs = 15 #but requires more epochs to train\n",
    "\n",
    "def my_loss_wrapper_fit(inputs,mysign = 1):\n",
    "    x  = inputs #x.shape = (?,?,4)\n",
    "    # Reshaping to correct format\n",
    "    x = tf.gather(x, np.arange(batch_size))\n",
    "    x = tf.gather(x, np.arange(51), axis = 1) # Axis corressponds to (max) number of particles in each event\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Getting theta0:\n",
    "    if train_theta == False:\n",
    "        theta0 = model_fit.layers[-1].get_weights() #when not training theta, fetch as np array \n",
    "    else:\n",
    "        theta0 = model_fit.trainable_weights[-1] #when training theta, fetch as tf.Variable\n",
    "        \n",
    "    #Creating theta_prime\n",
    "    alphaS = K.ones(shape =x.shape[0:2])*theta0 # Fitting parameter\n",
    "    aLund = K.ones(shape =x.shape[0:2])*0.68 # Fixed at default\n",
    "    probStoUD = K.ones(shape =x.shape[0:2])*0.217 # Fixed at default\n",
    "    \n",
    "    theta_prime = K.stack((alphaS, aLund, probStoUD), axis = 2)\n",
    "    \n",
    "    data = K.concatenate((x, theta_prime), axis =2)\n",
    "    # print(data.shape) # = (batch_size, 51, 7); correct format to pass to DCTR\n",
    "   \n",
    "    w = reweight(data) #NN reweight\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        # Mean Squared Loss\n",
    "        t_loss = mysign*(y_true*(y_true - y_pred)**2+(w)*(1.-y_true)*(y_true - y_pred)**2)\n",
    "        # Categorical Cross-Entropy Loss\n",
    "        \n",
    "        #Clip the prediction value to prevent NaN's and Inf's\n",
    "        '''\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        \n",
    "        t_loss = -mysign*((y_true)*K.log(y_pred) +w*(1-y_true)*K.log(1-y_pred))\n",
    "        '''\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss\n",
    "    \n",
    "for k in range(epochs):    \n",
    "    print(\"Epoch: \",k )\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        train_theta = False\n",
    "        model_fit.layers[i].trainable = True\n",
    "        pass\n",
    "    train_theta = False\n",
    "    model_fit.layers[-1].trainable = False\n",
    "    #model.summary()    \n",
    "    \n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit,1),metrics=['accuracy'])\n",
    "    print(\"Training g\")\n",
    "    model_fit.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1,callbacks=callbacks)\n",
    "\n",
    "    #Now, fix g and train \\theta.\n",
    "\n",
    "    for i in range(len(model_fit.layers)-1):\n",
    "        model_fit.layers[i].trainable = False\n",
    "        pass    \n",
    "    train_theta = True\n",
    "    model_fit.layers[-1].trainable = True\n",
    "    \n",
    "    model_fit.compile(optimizer='adam', loss=my_loss_wrapper_fit(myinputs_fit,-1),metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    print(\"Training theta\")\n",
    "    model_fit.fit(X_train, Y_train, epochs=1, batch_size=batch_size,validation_data=(X_test, Y_test),verbose=1,callbacks=callbacks)    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_vals, label='Model Fit')\n",
    "plt.hlines(0.16, 0, len(fit_vals), label = 'Truth')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(r'$\\theta_{fit}$')\n",
    "plt.legend()\n",
    "plt.title(\"(Starting at fit = 0.12) \\nN = {:.0e}, batch_size = {:.0f}, Epochs = {:.0f}\".format(len(X_default), batch_size, epochs*2))\n",
    "plt.savefig(\"(Starting at fit = 0.12) N = {:.0e}, batch_size = {:.0f}, Epochs = {:.0f}.png\".format(len(X_default), batch_size, epochs))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
