{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Mass DCTR 1D - $m_{jjj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to train and validate a DCTR model that reweights __only__ $m_T = 172.5 \\rightarrow 175.0$ using only reconstructed hadronic mass $m_{jjj}$ for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:26.409038Z",
     "start_time": "2020-06-09T19:22:26.405542Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.329199Z",
     "start_time": "2020-06-09T19:22:26.411360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/csuaysom/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping\n",
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "\n",
    "import inspect\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.334239Z",
     "start_time": "2020-06-09T19:22:28.331394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to downloaded data from Zenodo\n",
    "data_dir0 = 'DCTRFitting/'\n",
    "data_dir1 = 'DCTRFitting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.358508Z",
     "start_time": "2020-06-09T19:22:28.336069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287065, 1)\n",
      "(294294, 1)\n"
     ]
    }
   ],
   "source": [
    "# fetch m_jjj vals from default dataset\n",
    "train_dataset_0_mjjj = np.load(data_dir0 + 'part_172_5_6j_obs.npy')[:, :1]\n",
    "train_dataset_0_mjjj_x4 = np.load(data_dir1 +\n",
    "                                  'part_172_5_6j_obs_x4.npy')[:, :1]\n",
    "# combine orignal and x4 samples\n",
    "train_dataset_0_mjjj = np.concatenate(\n",
    "    (train_dataset_0_mjjj, train_dataset_0_mjjj_x4))\n",
    "\n",
    "print(np.shape(train_dataset_0_mjjj))\n",
    "\n",
    "# fetch m_jjj vals from varied dataset\n",
    "train_dataset_1_mjjj = np.load(data_dir0 + 'part_175_0_6j_obs.npy')[:, :1]\n",
    "train_dataset_1_mjjj_x4 = np.load(data_dir1 +\n",
    "                                  'part_175_0_6j_obs_x4.npy')[:, :1]\n",
    "# combine orignal and x4 samples\n",
    "train_dataset_1_mjjj = np.concatenate(\n",
    "    (train_dataset_1_mjjj,\n",
    "     train_dataset_1_mjjj_x4))  #[:len(train_dataset_0_mjjj)]\n",
    "\n",
    "print(np.shape(train_dataset_1_mjjj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will see an unequal number of events from the uniformly sampled mass data and the fixed mass data. We will have to correct this with a liklihood ratio factor when reweighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.363704Z",
     "start_time": "2020-06-09T19:22:28.360226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0251824499677773\n"
     ]
    }
   ],
   "source": [
    "X0 = train_dataset_0_mjjj\n",
    "X1 = train_dataset_1_mjjj\n",
    "\n",
    "print(len(X1)/len(X0)) # different sizes if != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.373286Z",
     "start_time": "2020-06-09T19:22:28.365134Z"
    }
   },
   "outputs": [],
   "source": [
    "Y0 = np.zeros_like(X0[:,0])\n",
    "Y1 = np.ones_like(X1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.396746Z",
     "start_time": "2020-06-09T19:22:28.377130Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X0, X1), axis = 0)\n",
    "X /= 100.\n",
    "\n",
    "Y = np.concatenate((Y0, Y1), axis = 0)\n",
    "Y = to_categorical(Y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.441945Z",
     "start_time": "2020-06-09T19:22:28.399189Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = data_split(X, Y, test=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.447433Z",
     "start_time": "2020-06-09T19:22:28.443674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465088, 1)\n",
      "(465088, 2)\n",
      "(116271, 1)\n",
      "(116271, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:22:28.535341Z",
     "start_time": "2020-06-09T19:22:28.449015Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input((1,))\n",
    "hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(hidden_layer_3)\n",
    "\n",
    "dctr = Model(inputs = inputs, outputs = outputs)\n",
    "dctr.compile(loss='categorical_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has a tendency to initialize at trivial minima of the loss function (loss ~ 8 or loss ~7); the mode's outputs are all [1, 0] or all [0, 1] respecively in these cases. We do 100 iterations of initializations to explore the fraction of initiziations that succeed in being able to train a non-trivial model(loss after first epoch ~1), and keep the weights from such a model to complete the rest of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:27:21.110803Z",
     "start_time": "2020-06-09T19:22:28.536824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.6933 - acc: 0.5027 - val_loss: 0.6931 - val_acc: 0.5061\n",
      "Success\n",
      "Iteration:  1\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6931 - acc: 0.5044 - val_loss: 0.6930 - val_acc: 0.5061\n",
      "Success\n",
      "Iteration:  2\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6932 - acc: 0.5049 - val_loss: 0.6931 - val_acc: 0.5061\n",
      "Success\n",
      "Iteration:  3\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6934 - acc: 0.5030 - val_loss: 0.6932 - val_acc: 0.4944\n",
      "Success\n",
      "Iteration:  4\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6933 - acc: 0.5037 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Success\n",
      "Iteration:  5\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6931 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5170\n",
      "Success\n",
      "Iteration:  6\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6932 - acc: 0.5046 - val_loss: 0.6933 - val_acc: 0.5061\n",
      "Success\n",
      "Iteration:  7\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6932 - acc: 0.5040 - val_loss: 0.6931 - val_acc: 0.4993\n",
      "Success\n",
      "Iteration:  8\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6932 - acc: 0.5047 - val_loss: 0.6931 - val_acc: 0.5190\n",
      "Success\n",
      "Iteration:  9\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.6932 - acc: 0.5040 - val_loss: 0.6930 - val_acc: 0.5061\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "n_fail1 = 0\n",
    "n_fail2 = 0\n",
    "n_succ = 0\n",
    "iterations = 10\n",
    "\n",
    "dctr_weights = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"Iteration: \", i)\n",
    "\n",
    "    K.clear_session()\n",
    "    inputs = Input((1, ))\n",
    "    hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "    hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "    hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "\n",
    "    outputs = Dense(2, activation='softmax')(hidden_layer_3)\n",
    "\n",
    "    dctr = Model(inputs=inputs, outputs=outputs)\n",
    "    dctr.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='Adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    history = dctr.fit(X_train,\n",
    "                       Y_train,\n",
    "                       epochs=1,\n",
    "                       batch_size=1000,\n",
    "                       validation_data=(X_val, Y_val),\n",
    "                       verbose=2)\n",
    "    if history.history['val_loss'][0] > 8:\n",
    "        # Fail case 1, model output [1, 0] for all preds\n",
    "        n_fail1 += 1\n",
    "        print(\"Fail (case 1)\")\n",
    "        pass\n",
    "    elif history.history['val_loss'][0] > 7:\n",
    "        # Fail case 2, , model output [0, 1] for all preds\n",
    "        n_fail2 += 1\n",
    "        print(\"Fail (case 2)\")\n",
    "        pass\n",
    "    else:  \n",
    "        # success\n",
    "        n_succ += 1\n",
    "        print(\"Success\")\n",
    "        # remember successful weights\n",
    "        dctr_weights = dctr.get_weights()\n",
    "        pass\n",
    "\n",
    "\n",
    "n_fail = n_fail1 + n_fail2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:27:21.120168Z",
     "start_time": "2020-06-09T19:27:21.113095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initializations failed:  0 / 10\n",
      "Percentage of initializations failed: 0.0 %\n",
      "Number of initializations succeeded:  10 / 10\n",
      "Percentage of initializations succeeded: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of initializations failed: \", n_fail, \"/\", iterations)\n",
    "print(\"Percentage of initializations failed:\", (100*n_fail/iterations), \"%\")\n",
    "\n",
    "print(\"Number of initializations succeeded: \", n_succ, \"/\", iterations)\n",
    "print(\"Percentage of initializations succeeded:\", (100*n_succ/iterations), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:42.353754Z",
     "start_time": "2020-06-09T19:27:21.122084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6930 - acc: 0.5062 - val_loss: 0.6931 - val_acc: 0.5061\n",
      "Epoch 2/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6931 - acc: 0.5056 - val_loss: 0.6930 - val_acc: 0.5061\n",
      "Epoch 3/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6930 - acc: 0.5065 - val_loss: 0.6931 - val_acc: 0.5061\n",
      "Epoch 4/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6930 - acc: 0.5068 - val_loss: 0.6930 - val_acc: 0.5069\n",
      "Epoch 5/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6930 - acc: 0.5062 - val_loss: 0.6930 - val_acc: 0.5076\n",
      "Epoch 6/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6930 - acc: 0.5082 - val_loss: 0.6930 - val_acc: 0.5083\n",
      "Epoch 7/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6929 - acc: 0.5090 - val_loss: 0.6929 - val_acc: 0.5083\n",
      "Epoch 8/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6929 - acc: 0.5095 - val_loss: 0.6928 - val_acc: 0.5122\n",
      "Epoch 9/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6928 - acc: 0.5107 - val_loss: 0.6932 - val_acc: 0.5095\n",
      "Epoch 10/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6927 - val_acc: 0.5127\n",
      "Epoch 11/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6928 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5185\n",
      "Epoch 12/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6927 - acc: 0.5129 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 13/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6927 - acc: 0.5135 - val_loss: 0.6925 - val_acc: 0.5133\n",
      "Epoch 14/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6926 - acc: 0.5151 - val_loss: 0.6926 - val_acc: 0.5190\n",
      "Epoch 15/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6926 - acc: 0.5150 - val_loss: 0.6924 - val_acc: 0.5160\n",
      "Epoch 16/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6926 - acc: 0.5149 - val_loss: 0.6924 - val_acc: 0.5169\n",
      "Epoch 17/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6925 - acc: 0.5162 - val_loss: 0.6930 - val_acc: 0.5078\n",
      "Epoch 18/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6924 - acc: 0.5168 - val_loss: 0.6923 - val_acc: 0.5190\n",
      "Epoch 19/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6923 - acc: 0.5169 - val_loss: 0.6925 - val_acc: 0.5149\n",
      "Epoch 20/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6923 - acc: 0.5168 - val_loss: 0.6922 - val_acc: 0.5174\n",
      "Epoch 21/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6923 - acc: 0.5173 - val_loss: 0.6927 - val_acc: 0.5132\n",
      "Epoch 22/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6922 - acc: 0.5178 - val_loss: 0.6921 - val_acc: 0.5165\n",
      "Epoch 23/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6921 - acc: 0.5171 - val_loss: 0.6922 - val_acc: 0.5141\n",
      "Epoch 24/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6921 - acc: 0.5173 - val_loss: 0.6921 - val_acc: 0.5155\n",
      "Epoch 25/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6921 - acc: 0.5170 - val_loss: 0.6920 - val_acc: 0.5166\n",
      "Epoch 26/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6920 - acc: 0.5179 - val_loss: 0.6919 - val_acc: 0.5173\n",
      "Epoch 27/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6920 - acc: 0.5179 - val_loss: 0.6923 - val_acc: 0.5155\n",
      "Epoch 28/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6920 - acc: 0.5180 - val_loss: 0.6920 - val_acc: 0.5165\n",
      "Epoch 29/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6920 - acc: 0.5181 - val_loss: 0.6919 - val_acc: 0.5181\n",
      "Epoch 30/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6921 - acc: 0.5170 - val_loss: 0.6923 - val_acc: 0.5158\n",
      "Epoch 31/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5183 - val_loss: 0.6918 - val_acc: 0.5176\n",
      "Epoch 32/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5186 - val_loss: 0.6919 - val_acc: 0.5164\n",
      "Epoch 33/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5180 - val_loss: 0.6918 - val_acc: 0.5181\n",
      "Epoch 34/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5179 - val_loss: 0.6918 - val_acc: 0.5181\n",
      "Epoch 35/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5185 - val_loss: 0.6920 - val_acc: 0.5180\n",
      "Epoch 36/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5182 - val_loss: 0.6918 - val_acc: 0.5170\n",
      "Epoch 37/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5184 - val_loss: 0.6918 - val_acc: 0.5182\n",
      "Epoch 38/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5183 - val_loss: 0.6920 - val_acc: 0.5175\n",
      "Epoch 39/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5187 - val_loss: 0.6918 - val_acc: 0.5179\n",
      "Epoch 40/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5184 - val_loss: 0.6919 - val_acc: 0.5191\n",
      "Epoch 41/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5183 - val_loss: 0.6918 - val_acc: 0.5178\n",
      "Epoch 42/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5183 - val_loss: 0.6919 - val_acc: 0.5167\n",
      "Epoch 43/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5180 - val_loss: 0.6919 - val_acc: 0.5175\n",
      "Epoch 44/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5183 - val_loss: 0.6920 - val_acc: 0.5173\n",
      "Epoch 45/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6918 - acc: 0.5188 - val_loss: 0.6917 - val_acc: 0.5191\n",
      "Epoch 46/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5185 - val_loss: 0.6920 - val_acc: 0.5185\n",
      "Epoch 47/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5182 - val_loss: 0.6919 - val_acc: 0.5183\n",
      "Epoch 48/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5181 - val_loss: 0.6924 - val_acc: 0.5158\n",
      "Epoch 49/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6918 - acc: 0.5186 - val_loss: 0.6918 - val_acc: 0.5176\n",
      "Epoch 50/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6918 - acc: 0.5191 - val_loss: 0.6919 - val_acc: 0.5173\n",
      "Epoch 51/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5184 - val_loss: 0.6919 - val_acc: 0.5186\n",
      "Epoch 52/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6918 - acc: 0.5187 - val_loss: 0.6918 - val_acc: 0.5174\n",
      "Epoch 53/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5179 - val_loss: 0.6920 - val_acc: 0.5185\n",
      "Epoch 54/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6919 - acc: 0.5184 - val_loss: 0.6919 - val_acc: 0.5170\n",
      "Epoch 55/200\n",
      "465088/465088 [==============================] - 3s 6us/step - loss: 0.6918 - acc: 0.5190 - val_loss: 0.6927 - val_acc: 0.5164\n"
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    dctr.set_weights(dctr_weights)\n",
    "    history = dctr.fit(X_train,\n",
    "                   Y_train,\n",
    "                   epochs=200,\n",
    "                   batch_size=1000,\n",
    "                   validation_data=(X_val, Y_val),\n",
    "                   callbacks=[earlystopping],\n",
    "                   verbose=1)\n",
    "except:\n",
    "    print(\n",
    "        \"Model did not have any successful initializations, will not continue training.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:42.824414Z",
     "start_time": "2020-06-09T19:29:42.356710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],     label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val loss')\n",
    "plt.legend(loc=0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:42.832625Z",
     "start_time": "2020-06-09T19:29:42.826485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57710, 1)\n",
      "(59119, 1)\n"
     ]
    }
   ],
   "source": [
    "test_dataset_0_mjjj = np.load(data_dir0 + 'part_172_5_6j_obs.npy')[:, :1]\n",
    "test_dataset_1_mjjj = np.load(data_dir0 + 'part_175_0_6j_obs.npy')[:, :1]\n",
    "\n",
    "print(np.shape(test_dataset_0_mjjj))\n",
    "print(np.shape(test_dataset_1_mjjj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:42.839249Z",
     "start_time": "2020-06-09T19:29:42.834516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define labels for legends\n",
    "label_0 = r'$m_T=172.5$'\n",
    "\n",
    "label_1 = r'$m_T=175.0$'\n",
    "\n",
    "def make_legend():\n",
    "    ax = plt.gca()\n",
    "    leg = ax.legend(frameon=False)\n",
    "    leg._legend_box.align = \"left\"\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reweighting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must calculate two liklihood ratios during reweighting: the first because the training datasets were different sizes, and the second because the validation datasets are different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:42.848347Z",
     "start_time": "2020-06-09T19:29:42.841034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "def reweight(default_dataset_172_5):\n",
    "\n",
    "    data_input = default_dataset_172_5/100.\n",
    "\n",
    "    f = dctr.predict(data_input)\n",
    "    weights = f[:, 1] / f[:, 0]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:43.346244Z",
     "start_time": "2020-06-09T19:29:42.850507Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = reweight(default_dataset_172_5=test_dataset_0_mjjj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:29:43.366256Z",
     "start_time": "2020-06-09T19:29:43.348331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3392526\n",
      "1.1187704\n"
     ]
    }
   ],
   "source": [
    "print(max(weights))\n",
    "print(max(1/weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:33:42.352876Z",
     "start_time": "2020-06-09T19:33:41.814032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEdCAYAAADEuPqOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3Xu8XdO99/HP111R1xSVsKM4GhwVeVBaRQ6lWnHOUeVUxaXH03JanJ4e0fZ5qNZTfdqDtu4vHFH3ulQQ1ZTQlrok7hKXlJBEVAhBKcLv/DHGipWVtdaee++59tor+/t+vdZrrTnGvIy559zrt8aYY46piMDMzKwMy7S7AGZmtvRwUDEzs9I4qJiZWWkcVMzMrDQOKmZmVhoHFTMzK42DipmZlcZBxczMSuOg0o8kdUkKSRcNhPWYmZVt0AQVSdvmL+J7GuQfmPND0vA6+StL+pukNyWt2PoSl8uBqHck7SfpF5L+IOm1/De8pMn8h1SdR41e79Uss7akr0q6TtIMSW9JWiDpj5IOl9Sj/1NJM5ts+4Xe/i2suJ6cN705Z/JypR5nSUMlXSjpeUlv5/WfLmnNnqxnuZ5uuIM9ALwCbCvpwxHxWk3+aCAAAbsBF9Tk7wSsCEyKiLd7WYY5wMeBBb1c3vrf94CtgTeA2cDm3cz/IPD9BnmfJp1bN9ekfxE4G5gLTAaeA9YF/gk4H9hL0hejZ2MqLQBOr5P+Rg/WYb3Xk/OmN+dMRSnHWdLHgLuAjwDXA48D2wFHA3tK2ikiXi60sogYNC/gWlLg+EKdvKeB24CXgEvr5P+/vOxxA2A/unJZLmrlMn4FwK7ApqQfG7vkv+ElvVzXn/Ly+9Sk7wZ8AVimJn09UoAJ4J97sJ2ZwMx2/+0G86us86bROVP2cQZuydv5Rk36qTn9nKLrGjTNX9mt+X236kRJXcDwnH8H6YSoVVnm1upESdtLulrSC5LekTRL0rmSPlq7gkZNUEqOljQtN7HNkXSGpNVzFXRmox3K67xC0kt52SmSPl8zz4nAM3lybE01+ZA8zz6SbpU0N1d9n5d0h6QjG227Tll2zev8qaSRkn4taX5uyrlO0np5vhGSLpP0Ys67UdKGRbfTnyJickQ8Ffk/rLckbQXsQKqt3lSzjdsi4oaIeL8m/QXgnDy5S1+2XzZJG/e0WaTBepa6cwbKOW+anTNlyrWUPUhB6sya7BOAvwJfkbRKkfUNtqByW34fXZM+uip/MrC+pBGVTEkfBkaRms/ur0o/DLgT2CsvdzowBfgqMKUHJ/2ZednVgfOAy0kHeRKwfJPlNgLuJdVCfglcCWwJXC+pOjDeDvwsf36IVNWuvB6UdASpyjsCuAH4L2AisDJwaMF9ABiZ3zcD/gi8R2pGfA7YF7hQ0hdymVcFxgNPAnsDF/dgO53oiPx+QUQs0T7exLv5fWEPt7eipIMkfSf/YNlV0rI9XEddktYg/fialD/3hc+ZxoqcM2Uc58p3xW/r/LB5nfQd9yFSgOvWYLqmQkRMlzQX2FLSkIiYl7N2I7VB3ge8VpU2LX/+DLAscHvljy5pM9KvyJnAZyJiTmU7kkYDvyV9kf9jszJJ+jTwddI/yvYR8WpO/w7wO+CjwLMNFt8FODEiFrXHSroM+A3wbVKgIyJuz7Wdo4EHI+LEmjJcALwDbB0RL9bkrdOs/DUqXxDbATtExMN5HSeRviT2ALYBdo+IP+W8FYAZwM6SVoqIv/Vge0uQdAzQky+6ByPi133ZZnckrQwcRPrCPL8Hyy0HHJwnf9PDza5H+qFR7RlJh0bEHT1c12Ii4lVJZwI/An4rafeI6O11Qp8zdfTgnCnjOP9dfn+yQf5TpOOwGTUtNXW1u+2xv1/5AASwf1Xa88DEqum/ANdWTZ+WlzmqTtreDbZzHenX5WpVaV3UXNcgnTABHFxnHTvlvJk16ZX1zASWrbPcs8BLDZa5qM78U0lV3DX7+LednrexZ528B3LeQXXyJuW8tUs4vjPzuoq+lvh7NFn3LvSibRwYm5e7sYfL/TQvd1MPlzuB9KNoXdIvzC1JP4DeB94k/Xgo439pXC7f3cCHfc6Ud94UOWfKOs6k1pEAvtog/+Scf3yh9ZVxcnXSi9Scs+jCE6k3VgDfrprnSmA++cIpqckogM2r5rk7p/1/4MQ6rztz/rZVy3TVnpSkL/QANq5T1mVJzR8za9Ir6/l1g338I/Beg2WW+IcA/j3nzSUFy32BIT38u65C+lX15wb584GXgeXr5D0JvFY1vUeBf+wlgnA/nDs9/nLIy1XOhSU6iDRZ5pt5menAWiWVvxKkrmsyz8wCf/t6r1/1ojxL/TnT2/OmN+dMT45zzfylBpVB1fyVVapvo2veb6ua53Zgf2AbSc8BWwFzIuLxqnnWzu/f7mZ7q3aTv3p+/0ttRkS8J6lZN75XG6QvpAfXyyLiVEkvAUeSvsyOAULSHaRgO6XAarbO2/xdbYZSR4g1SbW/d2vyVgU2IQXCij8A61dN3wtcRfpnqZhfoExtJ2kLYEdSt9KJBZf5N1LT6TRgdESUta/nAN8Cdm4yz5+Bos1Jy5B6OEHqNdlTPmfq6M05U6PIca5WabpcvUF+Jb3R981iBl1QiYjnJP0Z2ETSMFL18VVSVbticn7fjdSUJJZsS1x0IGLJe156orLsuqRuzYvkC25rk3p/tFREXAxcnC+87ki6FnQYcIukzeOD60+NVNrGp9bJ27ZJ3jakv++iDhAR8RbwFoCk1YGhwJ2RekM1NQDbx3t0gT6X/zTgUVJAebGbRXqicgwb9uKJiNpOLHUp3ZB5ASmo/Ar4Ri/K43Omvt526qjo9jjXeCK/b9Ygv/LDodE1l8UMuqCS3Qp8DPgHUtX0jqjq9RARjyvdkVoJKpVlqt1NOvE/Td+6+z1A+if5FDVBhdTboqxjVDk5m/YMidRRYCIwMX9xHEb6xXNNN+uvfEHUq9Vs2yRvm/x+f528ynpF/S+Xeo4h9YorajzQki8ISSsBX+GDHk3dzX8ccArpZrjdI6I3v/6bqfTeqT3PeiSfFxeS2v2vBv4lInraOw18ziyhp+dMAz09zpUf0XtIWqb6u1DSaqRru2+SvvO6Ndi6FFdUmrqOJVWxJ9eZZzIpYOyRp2uDyhmk6x2n5Z5gi5G0Qu7Z1Z1Kt8jv5l9Yi5Yn3XBZlldI7aJLdHPO3RBVZ5mP5Pc3C6x/JKkH2aN18pr96qx8sTT6gtiW1OnguQJlICK6IkI9eB1SZL299EXS+XVzRMxqNqOk/0MKKFNJNZSmAUXSxyRtLmn5mvSP17ufIDcnnZEnGw4zU9AqwBakm4kP7GVAAZ8z9RQ6Z3p7nOudNxHxZ1Jv1S7gqJpFvk863r+MiL8W2YHBWlO5jfQFu1XVdK3JwIGkmyKfiKouw7CoNnMY6RfbY5J+Q6oeLk/64v40qRradFiPiLhD0nmkKu9jkq4hBasvkJrYnif15uiTiHhDadyzT0u6NJf1PWACqafaG5LuJl2oVS7//yL9Uy/R5l1NaSy0EcDDEfFOnVm2BZ6N+sM8jCQ1W0xvsPqRLN402a8k7UvquACp+ybAJ/XBDawvRcR/NFi80oxxXjfbGAucRDoefwC+WSfGz4yIi6qmbyX9uh5OOmYVXwK+Jen3pFr266Ra+d7ASqRaaPV1hh6LiNdzt/m3ehtQluZzBvp03hQ6Z+j9cW503hxJGqbl5/nYTge2J93D8iTw3W7K84Ge9ixYWl580KNrHqA6+ZvwQa+RM5usZyvgonxg3yZdDHwUOBfYrWbeLur0wCLVGI8ljbfzNimQnEm6QPY6qQ232/VU5d+eDm3dfbqB1KPm/byOQ4CvkQLL06RayXzSP+V/UtUlusnfYNu8rnPr5G2U866pk7ciKYDe3WTdjwM/auN5cmLVeVDvNbPBcpVehbOo0+27h9sI0j1S1cvMzOldNemfId08+zjpWuG7+RyfRLrnZYlzvU1/16X2nOntedPDc6ZXx7nReZPzhgH/TeoF+g7pO+10enirgfLKbACStCnpV8IVEXFgu8vT33Ivn9eAL0XEr9pdHhv4fM6032C9pjKgSFpPNcObS/oQH4w+el3/l2pAWKKXj1k3fM602WC9pjLQHAMcKOl2UtVzPdL9M0NJQ14P1l9cI0nXlfrUW8kGFZ8zbebmrwEgXxj7D+ATwFqkmxefBC4DTo+am7/MzAYqBxUzMyvNoGv+WmeddaKrq6vdxTAz6yhTp059KSKGdDffoAsqXV1dTJlSZCgrMzOrkNToERyLce8vMzMrjYOKmZmVxkHFzMxK46BiZmalcVAxM7PSOKiYmVlpHFTMzKw0DipmZlYaBxUzMyvNoLuj3pZOXeNuWvR55il7t7EkZoObaypmZlYaBxUzMyuNg4qZmZXGQcXMzErjoGJmZqVxUDEzs9I4qJiZWWkcVMzMrDQOKmZmVpqWBRVJF0p6UdKjVWk/kfS4pIclXSdpjaq84yXNkPSEpM9Wpe+Z02ZIGleVPlzSPTn9SkkrtGpfzMysmFbWVC4C9qxJmwRsGRF/DzwJHA8gaQRwALBFXuYsSctKWhY4E9gLGAEcmOcF+DFwWkRsArwCHN7CfTEzswJaFlQi4vfA/Jq030bEwjx5NzA0fx4DXBERb0fEM8AMYLv8mhERT0fEO8AVwBhJAnYDrs7Ljwf2bdW+mJlZMe28pnIYcHP+vAEwqypvdk5rlL428GpVgKqkm5lZG7UlqEj6LrAQuLSftneEpCmSpsybN68/NmlmNij1e1CRdAjweeDLERE5eQ4wrGq2oTmtUfrLwBqSlqtJrysizouIURExasiQIaXsh5mZLalfg4qkPYH/BPaJiDersiYAB0haUdJwYFPgXuA+YNPc02sF0sX8CTkYTQb2y8uPBa7vr/0wM7P6Wtml+HLgT8DfSZot6XDgDGA1YJKkByWdAxARjwFXAdOA3wBHRcR7+ZrJvwG3ANOBq/K8AMcB/y5pBukaywWt2hczMyumZU9+jIgD6yQ3/OKPiJOBk+ukTwQm1kl/mtQ7zMzMBgjfUW9mZqVxUDEzs9I4qJiZWWkcVMzMrDQOKmZmVhoHFTMzK42DipmZlcZBxczMSuOgYmZmpXFQMTOz0jiomJlZaRxUzMysNA4qZmZWGgcVMzMrjYOKmZmVxkHFzMxK46BiZmalcVAxM7PSOKiYmVlpCgcVSatIWraVhTEzs87WMKhIWkbSv0i6SdKLwOPAXEnTJP1E0ib9V0wzM+sEzWoqk4GPAccD60XEsIj4CPAp4G7gx5IO6ocymplZh1iuSd4/RMS7tYkRMR+4BrhG0vItK5mZmXWcZkFlNUkNMyNifr2gY2Zmg1ez5q+pwJT8Pg94Engqf57a3YolXSjpRUmPVqWtJWmSpKfy+5o5XZJ+LmmGpIcljaxaZmye/ylJY6vSt5X0SF7m52oWAc3MrF80DCoRMTwiNgZ+B3whItaJiLWBzwO/LbDui4A9a9LGAbdGxKbArXkaYC9g0/w6AjgbUhACTgC2B7YDTqgEojzPv1YtV7stMzPrZ0W6FO8QERMrExFxM7BjdwtFxO+B+TXJY4Dx+fN4YN+q9IsjuRtYQ9L6wGeBSbmp7RVgErBnzvtwRNwdEQFcXLUuMzNrkyJB5XlJ35PUlV/fBZ7v5fbWjYi5+fMLwLr58wbArKr5Zue0Zumz66TXJekISVMkTZk3b14vi25mZt0pElQOBIYA1wHX5s8H9nXDuYYRfV1PwW2dFxGjImLUkCFD+mOTZmaDUrPeX8CiLsRHS1olIv7ax+39RdL6ETE3N2G9mNPnAMOq5hua0+YAu9Sk357Th9aZ38zM2qjbmoqkHSVNA6bn6a0lndXL7U0AKj24xgLXV6UfnHuB7QAsyM1ktwB7SFozX6DfA7gl570maYfc6+vgqnWZmVmbdFtTAU4jXTCfABARD0naubuFJF1OqmWsI2k2qRfXKcBVkg4HngX2z7NPBD4HzADeBA7N25ov6QfAfXm+k3LNCeBIUg+zlYGb88vMzNqoSFAhImbV3AbyXoFlGl13GV1n3gCOarCeC4EL66RPAbbsrhxmZtZ/igSVWZJ2BCIPy3I0uSnMzMysWpHeX18j1SI2IF0M/wQNahVmZja4FamprBwRX65OkLRei8pjZmYdrEhN5RlJl0tauSptYsO5zcxs0CoSVB4B/gDcKeljOc2DN5qZ2RKKNH9FRJwl6SHgBknH0U93wpuZWWcpElQEEBF3ShoNXAVs3tJSmZlZRyoSVD5X+ZCHV9mVAqMUm5Wla9xNiz7PPGXvNpbEzLrTMKhIOigiLgEObPD8q9+3rFRmZtaRmtVUVsnvq/VHQczMrPM1DCoRcW5+/37/FcfMzDpZs+avnzdbMCK+WX5xzMyskzVr/prab6UwM7OlQrPmr/GN8szMzOrptkuxpCHAccAIYKVKekTs1sJymZlZByoyTMulpKHuhwPfB2bywUOzzMzMFikSVNaOiAuAdyPijog4DHAtxczMllDkjvp38/tcSXsDzwNrta5IZmbWqYoElR9KWh34FvAL4MPAsS0tlZmZdaRug0pE3Jg/LgB2bW1xzMyskxXp/TUc+AbQVT1/ROzTumKZmVknKtL89WvgAuAG4P3WFsesOY9YbDawFQkqf4uIpkO2mJmZQbEuxT+TdIKkT0oaWXn1ZaOSjpX0mKRHJV0uaSVJwyXdI2mGpCslrZDnXTFPz8j5XVXrOT6nPyHps30pk5mZ9V2RmspWwFdI96ZUmr+CXt6rImkD4JvAiIh4S9JVwAGkh4GdFhFXSDoHOBw4O7+/EhGbSDoA+DHwJUkj8nJbAB8Ffidps4h4rzflMjOzvitSU/kisHFEfCYids2vvt78uBywsqTlgA8Bc0lB6uqcPx7YN38ek6fJ+aOVnho2BrgiIt6OiGeAGcB2fSyXmZn1QZGg8iiwRlkbjIg5wE+B50jBZAFpRORXI2Jhnm02sEH+vAEwKy+7MM+/dnV6nWUWI+kISVMkTZk3b15Zu2JmZjWKNH+tATwu6T7g7Upib7sUS1qTVMsYDrwK/ArYszfrKioizgPOAxg1alS0cltmZoNZkaByQsnb/AfgmYiYByDpWmAnYA1Jy+XayFBgTp5/DjAMmJ2by1YHXq5Kr6hexszM2qBp85ekZYET80CSi736sM3ngB0kfShfGxkNTAMmA/vlecYC1+fPE/I0Of+2iIicfkDuHTYc2BS4tw/lMjOzPmpaU4mI9yS9L2n1iFhQxgYj4h5JVwP3AwuBB0hNUzcBV0j6YU67IC9yAfBLSTOA+aQeX0TEY7nn2LS8nqPc88vMrL2KNH+9ATwiaRLw10piX55RHxEnsGSz2tPU6b0VEX8j9UCrt56TgZN7Ww4zMytXkaBybX6ZmZk1VWSU4vH57vbNctITEfFus2XMzGxwKjJK8S6kmw9nAgKGSRobEb9vbdHMzKzTFGn++i9gj4h4AkDSZsDlwLatLJiZmXWeInfUL18JKAAR8SSwfOuKZGZmnapITWWKpPOBS/L0l4EprSuSmZl1qiJB5evAUaSRhQH+AJzVshKZmVnHKtL7623g1PwyMzNrqEjvr52AE4GNWPwZ9Ru3rlhmZtaJijR/XQAcSxqe3sOgmJlZQ0WCyoKIuLnlJTEzs45XJKhMlvQT0lAt1c9Tub9lpTIzs45UJKhsn99HVaX1+hn1Zma29CrS+2vX/iiImZl1voZ31Es6SFKz/I9J+lRrimVmZp2oWU1lbeABSVNJPb/mASsBmwCfAV4CxrW8hGY91DXupkWfZ56ydxtLYjb4NAwqEfEzSWeQrp3sBPw98BYwHfhKRDzXP0U0M7NO0e3jhIFJ+WVmZtZUkVGKzczMCnFQMTOz0jiomJlZaYoMKLki8M9AF4sPKHlS64plZmadqMgd9dcDC0jdit/uZl4zMxvEigSVoRGxZ5kblbQGcD6wJWnIl8OAJ4ArSTWimcD+EfGKJAE/Az4HvAkcUhl3TNJY4Ht5tT+MiPFlltPMzHqmyDWVuyRtVfJ2fwb8JiI2B7Ym3fsyDrg1IjYFbuWDGyv3AjbNryOAswEkrQWcQBqbbDvgBElrllxOMzPrgSJB5VPAVElPSHpY0iOSHu7tBiWtDuxMek4LEfFORLwKjAEqNY3xwL758xjg4kjuBtaQtD7wWWBSRMyPiFdI99KUWqMyM7OeKdL8tVfJ2xxOGvLlvyVtTbpWczSwbkTMzfO8AKybP28AzKpafnZOa5S+BElHkGo5bLjhhuXshZmZLaHZgJEfzh9fb/DqreWAkcDZEbEN8FdqxhCLiCBdaylFRJwXEaMiYtSQIUPKWq2ZmdVo1vx1WX6fCkzJ71OrpntrNjA7Iu7J01eTgsxfcrMW+f3FnD8HGFa1/NCc1ijdzMzapGFQiYjP5/fhEbFxfq+8Nu7tBiPiBWCWpL/LSaOBacAEYGxOG0vqykxOP1jJDqTHG88FbgH2kLRmvkC/R04zM7M2KXJNBUn/RLpgH8AfIuLXfdzuN4BLJa0APA0cSgpwV0k6HHgW2D/PO5HUnXgGqUvxoQARMV/SD4D78nwnRcT8PpbLzMz6oMgd9WeRnqFyeU76mqTdI+Ko3m40Ih5k8ccTV4yuM28AdbcVERcCF/a2HGZmVq4iNZXdgI/nL3ckjQcea2mpzMysIxW5T2UGUN0Pd1hOMzMzW0zDmoqkG0jXUFYDpku6N09vD9zbP8UzM7NO0qz566f9VgozM1sqNHtG/R39WRAzM+t8fkiXmZmVptB9Kmb9rWvcTe0ugpn1QtOaiqRlJV3aX4UxM7PO1jSoRMR7wEb5znczM7OmijR/PQ3cKWkCaURhACLi1JaVyszMOlKRoPLn/FqGdM+KmZlZXd0GlYj4PoCkD0XEm60vkpmZdapuuxRL+qSkacDjeXrrPMikmZnZYorcp3I66XnwLwNExEOkZ8ybmZktptDNjxExqybpvRaUxczMOlyRC/WzJO0IhKTlgaOB6a0tlln3fIOk2cBTpKbyNdJDsjYAngc+QYOHZpmZ2eBWpPfXS8CX+6EsZmbW4Yr0/tpY0g2S5kl6UdL1kjbuj8KZmVlnKdL8dRlwFbA+8FHgV3zwvHozM7NFigSVD0XELyNiYX5dAqzU6oKZmVnnKdL762ZJ44ArSI8T/hIwUdJaABExv4XlMzOzDlIkqOyf3/93TfoBpCDj6ytmZgYUaP6KiOFNXr0OKPlZLQ9IujFPD5d0j6QZkq6sDLcvacU8PSPnd1Wt4/ic/oSkz/a2LGZmVo52Pk649ibKHwOnRcQmwCvA4Tn9cOCVnH5ang9JI0i1pS2APYGzJC3bT2U3M7M62hJUJA0F9gbOz9MCdgOuzrOMB/bNn8fkaXL+6Dz/GOCKiHg7Ip4BZgDb9c8emJlZPe2qqZwO/Cfwfp5eG3g1Ihbm6dmkO/jJ77MAcv6CPP+i9DrLLEbSEZKmSJoyb968MvfDzMyqFLn5cSdJq+TPB0k6VdJGvd2gpM8DL0bE1N6uo6ci4ryIGBURo4YMGdJfmzUzG3SK1FTOBt6UtDXwLdJTIC/uwzZ3AvaRNJPUTXk34GfAGpIqvdGGAnPy5znAMICcvzppGP5F6XWWMTOzNigSVBZGRJCuYZwREWfSh8cKR8TxETE0IrpIF9pvi4gvA5OB/fJsY4Hr8+cJeZqcf1suzwTggNw7bDiwKXBvb8tlZmZ9V+Q+ldclHQ8cBOwsaRlg+RaU5TjgCkk/BB4ALsjpFwC/lDQDmE8KRETEY5KuAqYBC4GjIsLPeTEza6MiQeVLwL8Ah0fEC5I2BH5SxsYj4nbg9vz5aer03oqIvwFfbLD8ycDJZZTFzMz6rkhQOTYijqtMRMRzkrZoYZnMzKxDFbmmsnudtL3KLoiZmXW+hjUVSV8HjgQ2lvRwVdZqwF2tLpiZmXWeZs1flwE3Az8CxlWlv+6Ric3MrJ6GzV8RsSAiZkbEgaT7QXaLiGeBZXIXXjMzs8UUuaP+BFJ33+Nz0grAJa0slJmZdaYivb/+EdgGuB8gIp6X1OubH80a6Rp3U7uLYGZ9VKT31zv5DvYAqIwDZmZmVqtIULlK0rmksbn+FbiVPGS9mZlZtW6bvyLip5J2B14DNgO+FxG/a3nJzMys4zS7T+V1cpMXoKqsr0n6G2m04u9GxK0tLJ+ZmXWQhkElIhpejM+P7d0SuDS/m5mZ9e7JjxHxXkQ8BPyi5PKYmVkH69PjhCPi3LIKYmZmna9dz6g3M7OlkIOKmZmVxkHFzMxK46BiZmalcVAxM7PSOKiYmVlpHFTMzKw0DipmZlYaBxUzMytNvwcVScMkTZY0TdJjko7O6WtJmiTpqfy+Zk6XpJ9LmiHpYUkjq9Y1Ns//lKSx/b0vZma2uHbUVBYC34qIEcAOwFGSRgDjgFsjYlPSM1vG5fn3AjbNryOAsyEFIeAEYHtgO+CESiAyM7P26PegEhFzI6LyaOLXgenABsAYYHyebTywb/48Brg4krtJDwtbH/gsMCki5kfEK8AkYM9+3BUzM6vR1msqkrqAbYB7gHUjYm7OegFYN3/eAJhVtdjsnNYo3czM2qRtQUXSqsA1wDER8Vp1XkQEHzwgrIxtHSFpiqQp8+bNK2u1ZmZWoy1BRdLypIByaURcm5P/kpu1yO8v5vQ5wLCqxYfmtEbpS4iI8yJiVESMGjJkSHk7YmZmi2lH7y8BFwDTI+LUqqwJQKUH11jg+qr0g3MvsB2ABbmZ7BZgD0lr5gv0e+Q0MzNrk4aPE26hnYCvAI9IejCnfQc4BbhK0uHAs8D+OW8i8DlgBvAmcChARMyX9APgvjzfSRExv392wczM6un3oBIRfwTUIHt0nfkDOKrBui4ELiyvdGZm1he+o97MzErjoGJmZqVxUDEzs9I4qJiZWWkcVMzMrDQOKmZmVhoHFTMzK42DipmZlcZBxczMSuOgYmZmpWnH2F9mHa9r3E2LPs88Ze82lsRsYHFNxczMSuOaillB1bUTM6vPQcWshoOHWe85qNig0oprIb6+YvYBBxVbqjWrdbhGYlY+X6g3M7PSOKiYmVlpHFTMzKw0DipmZlYaBxUzMyuNg4oSfF9CAAAGRklEQVSZmZXGQcXMzErjoGJmZqXp+KAiaU9JT0iaIWlcu8tjZjaYdXRQkbQscCawFzACOFDSiPaWysxs8OrooAJsB8yIiKcj4h3gCmBMm8tkZjZodfrYXxsAs6qmZwPb184k6QjgiDz5hqQnerm9dYCXernsQLO07MuA2g/9uE+LD6h96SPvy8DT1/3YqMhMnR5UComI84Dz+roeSVMiYlQJRWq7pWVflpb9AO/LQLW07Et/7UenN3/NAYZVTQ/NaWZm1gadHlTuAzaVNFzSCsABwIQ2l8nMbNDq6OaviFgo6d+AW4BlgQsj4rEWbrLPTWgDyNKyL0vLfoD3ZaBaWvalX/ZDEdEf2zEzs0Gg05u/zMxsAHFQMTOz0jio1NHd0C+SVpR0Zc6/R1JX/5eyewX24xBJ8yQ9mF9fbUc5i5B0oaQXJT3aIF+Sfp739WFJI/u7jEUU2I9dJC2oOib/t7/LWJSkYZImS5om6TFJR9eZZ8Afl4L70RHHRdJKku6V9FDel+/Xmae1318R4VfVi3TB/8/AxsAKwEPAiJp5jgTOyZ8PAK5sd7l7uR+HAGe0u6wF92dnYCTwaIP8zwE3AwJ2AO5pd5l7uR+7ADe2u5wF92V9YGT+vBrwZJ1zbMAfl4L70RHHJf+dV82flwfuAXaomael31+uqSypyNAvY4Dx+fPVwGhJ6scyFrFUDWETEb8H5jeZZQxwcSR3A2tIWr9/Sldcgf3oGBExNyLuz59fB6aTRrmoNuCPS8H96Aj57/xGnlw+v2p7Y7X0+8tBZUn1hn6pPcEWzRMRC4EFwNr9UrriiuwHwD/nZomrJQ2rk98piu5vJ/hkbr64WdIW7S5MEbkJZRvSL+NqHXVcmuwHdMhxkbSspAeBF4FJEdHwmLTi+8tBZXC7AeiKiL8HJvHBrxdrn/uBjSJia+AXwK/bXJ5uSVoVuAY4JiJea3d5equb/eiY4xIR70XEJ0gjjGwnacv+3L6DypKKDP2yaB5JywGrAy/3S+mK63Y/IuLliHg7T54PbNtPZWuFpWLInoh4rdJ8ERETgeUlrdPmYjUkaXnSF/GlEXFtnVk64rh0tx+ddlwAIuJVYDKwZ01WS7+/HFSWVGTolwnA2Px5P+C2yFe9BpBu96OmbXsfUltyp5oAHJx7G+0ALIiIue0uVE9JWq/Svi1pO9L/6ED7wQKknl3ABcD0iDi1wWwD/rgU2Y9OOS6ShkhaI39eGdgdeLxmtpZ+f3X0MC2tEA2GfpF0EjAlIiaQTsBfSppBuuh6QPtKXF/B/fimpH2AhaT9OKRtBe6GpMtJPXDWkTQbOIF0EZKIOAeYSOppNAN4Ezi0PSVtrsB+7Ad8XdJC4C3ggAH4g6ViJ+ArwCO5DR/gO8CG0FHHpch+dMpxWR8Yr/QAw2WAqyLixv78/vIwLWZmVho3f5mZWWkcVMzMrDQOKmZmVhoHFTMzK42DipmZlcZBxawEkk6TdEzV9C2Szq+a/i9J/95k+bsKbGNmvRvu8gi6O/am3GZlc1AxK8edwI4AkpYB1gGqx4faEWgYOCKiL0Fhl8q2zdrNQcWsHHcBn8yftwAeBV6XtKakFYGPA/dL+rak+/IgnouedSHpjfy+jKSzJD0uaZKkiZL2q9rONyTdL+kRSZvnARC/Bhybn/Px6X7YV7OGfEe9WQki4nlJCyVtSKo1/Ik0GuwnSaPAPkKqUWxKeiyBgAmSds7D4Vf8E9AFjAA+Qho658Kq/JciYqSkI4H/iIivSjoHeCMiftrKfTQrwjUVs/LcRQoolaDyp6rpO4E98usB0qi3m5OCTLVPAb+KiPcj4gXSgIDVKoMdTiUFH7MBxTUVs/JUrqtsRWr+mgV8C3gN+G/gM8CPIuLcPmyjMqr0e/j/1wYg11TMynMX8Hlgfn6mxXxgDVIT2F2kwT0Py8/tQNIGkj5Ss447SQ9OW0bSuqQms+68TnoMrlnbOaiYlecRUq+vu2vSFkTESxHxW+Ay4E+SHiE9yrU2GFxDejriNOASUjPZgm62ewPwj75QbwOBRyk2G2AkrRoRb0haG7gX2ClfXzEb8Nwmazbw3JgftLQC8AMHFOskrqmYmVlpfE3FzMxK46BiZmalcVAxM7PSOKiYmVlpHFTMzKw0/wNfTUnXTdcdDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_val = 3\n",
    "bins = np.linspace(0, clip_val, 101)\n",
    "plt.hist(np.clip(weights, 0, clip_val), bins = bins)\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel('Jets per bin (normalized)')\n",
    "plt.title(\"Weights \" + label_0 + r'$\\rightarrow$ ' + label_1, fontsize = 20)\n",
    "#plt.savefig(\"Weights: Top Reweighting (fixed mass DCTR): m_{jjj} only.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:33:43.330556Z",
     "start_time": "2020-06-09T19:33:43.325484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define default plot styles\n",
    "plot_style_0 = {'histtype':'step', 'color':'black', 'linewidth':2, 'linestyle':'--', 'density':True}\n",
    "plot_style_1 = {'alpha':0.5, 'density':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T19:33:44.563035Z",
     "start_time": "2020-06-09T19:33:43.733184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"Top Reweighting (fixed mass DCTR): $m_{jjj}$ only\")\n",
    "bins = np.linspace(80,400,41)\n",
    "hist0 = plt.hist(test_dataset_0_mjjj, bins = bins, label = label_0, **plot_style_1)\n",
    "hist1 = plt.hist(test_dataset_1_mjjj, bins = bins, label = label_1, **plot_style_0)\n",
    "hist2 = plt.hist(test_dataset_0_mjjj, bins = bins, label = label_0 + ' wgt.', weights=weights, **plot_style_1)\n",
    "\n",
    "plt.xlabel('mjj')\n",
    "plt.ylabel('Jets per bin (normalized)')\n",
    "plt.xlim([80,400])\n",
    "make_legend()\n",
    "#plt.savefig(\"Top Reweighting (fixed mass DCTR): m_{jjj} only.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(d):\n",
    "    f = dctr(d/100)\n",
    "    weights = f[:, 1] / f[:, 0]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting with data of mass 175 as unknown parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "myinputs = Input(shape=(1,), dtype = tf.float32)\n",
    "\n",
    "x = Dense(128, activation='relu')(myinputs)\n",
    "x2 = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x2)\n",
    "          \n",
    "model = Model(inputs=myinputs, outputs=predictions)\n",
    "#model.summary()\n",
    "batch_size = 1000\n",
    "\n",
    "def my_loss_wrapper(inputs,val=0.0):\n",
    "    x = inputs\n",
    "    weight = reweight(x)\n",
    "    def my_loss(y_true,y_pred):\n",
    "        print(\"y_true shape\", y_true.shape)\n",
    "        print(\"y_pred shape\", y_pred.shape)\n",
    "        t_loss = y_true*(y_true - y_pred)**2+(weight**2)*(1.-y_true)*(y_true - y_pred)**2\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 10s 22us/step - loss: 0.2515 - acc: 0.5030 - val_loss: 0.2514 - val_acc: 0.4938\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2515 - acc: 0.5032 - val_loss: 0.2514 - val_acc: 0.5100\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2514 - acc: 0.5052 - val_loss: 0.2515 - val_acc: 0.5061\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2514 - acc: 0.5056 - val_loss: 0.2513 - val_acc: 0.5139\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2514 - acc: 0.5084 - val_loss: 0.2513 - val_acc: 0.5080\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2513 - acc: 0.5087 - val_loss: 0.2513 - val_acc: 0.5079\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2513 - acc: 0.5104 - val_loss: 0.2513 - val_acc: 0.5095\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2513 - acc: 0.5118 - val_loss: 0.2513 - val_acc: 0.5122\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2513 - acc: 0.5125 - val_loss: 0.2512 - val_acc: 0.5137\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2513 - acc: 0.5127 - val_loss: 0.2512 - val_acc: 0.5139\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 27us/step - loss: 0.2512 - acc: 0.5148 - val_loss: 0.2511 - val_acc: 0.5160\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2512 - acc: 0.5156 - val_loss: 0.2513 - val_acc: 0.5109\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2511 - acc: 0.5159 - val_loss: 0.2511 - val_acc: 0.5164\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2510 - acc: 0.5169 - val_loss: 0.2510 - val_acc: 0.5186\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2510 - acc: 0.5158 - val_loss: 0.2510 - val_acc: 0.5180\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2510 - acc: 0.5170 - val_loss: 0.2510 - val_acc: 0.5169\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2509 - acc: 0.5171 - val_loss: 0.2509 - val_acc: 0.5178\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2509 - acc: 0.5174 - val_loss: 0.2510 - val_acc: 0.5191\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2509 - acc: 0.5175 - val_loss: 0.2509 - val_acc: 0.5185\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2509 - acc: 0.5175 - val_loss: 0.2509 - val_acc: 0.5181\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2509 - acc: 0.5176 - val_loss: 0.2510 - val_acc: 0.5165\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2509 - acc: 0.5183 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2509 - acc: 0.5180 - val_loss: 0.2510 - val_acc: 0.5163\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2509 - acc: 0.5180 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2509 - acc: 0.5178 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2510 - val_acc: 0.5158\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2509 - acc: 0.5174 - val_loss: 0.2509 - val_acc: 0.5168\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2509 - val_acc: 0.5172\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2513 - val_acc: 0.5095\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2508 - acc: 0.5179 - val_loss: 0.2510 - val_acc: 0.5181\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2509 - val_acc: 0.5188\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5169\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2508 - acc: 0.5179 - val_loss: 0.2509 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2508 - acc: 0.5182 - val_loss: 0.2509 - val_acc: 0.5154\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 4s 10us/step - loss: 0.2509 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5178 - val_loss: 0.2509 - val_acc: 0.5160\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2508 - val_acc: 0.5181\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2509 - val_acc: 0.5177\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5160\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5167\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5181\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2509 - acc: 0.5179 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5185\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5195\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2509 - val_acc: 0.5193\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2509 - val_acc: 0.5160\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5171\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5182 - val_loss: 0.2510 - val_acc: 0.5157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5170\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5131\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5182 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2509 - val_acc: 0.5176\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2512 - val_acc: 0.5144\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2509 - val_acc: 0.5177\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2509 - val_acc: 0.5164\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2509 - val_acc: 0.5174\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 10s 22us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5163\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5173\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2510 - val_acc: 0.5145\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5166\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5170\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2507 - val_acc: 0.5189\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2508 - val_acc: 0.5165\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5182\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 8us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2509 - val_acc: 0.5158\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 4s 8us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5168\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5165\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5181\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5184 - val_loss: 0.2509 - val_acc: 0.5160\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5169\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5168\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5182\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5162\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5156\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5172\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5196\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2507 - val_acc: 0.5187\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5162\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5149\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2509 - val_acc: 0.5168\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 19us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5165\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5159\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 4s 8us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 20us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2509 - val_acc: 0.5169\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5169\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2509 - val_acc: 0.5180\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 20us/step - loss: 0.2508 - acc: 0.5194 - val_loss: 0.2509 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2509 - val_acc: 0.5179\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5171\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5182\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 4s 8us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2510 - val_acc: 0.5147\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2510 - val_acc: 0.5170\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5182 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 20us/step - loss: 0.2508 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5165\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2511 - val_acc: 0.5144\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2510 - val_acc: 0.5152\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 3s 8us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5181 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 3s 8us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 9s 20us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2509 - val_acc: 0.5164\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5181\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 3s 7us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2509 - val_acc: 0.5158\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5164\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 14s 31us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5190\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5167\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2509 - val_acc: 0.5169\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5173\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 14s 31us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5161\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5178\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 14s 31us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2510 - val_acc: 0.5169\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5181\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 14s 31us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5173\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5195\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 14s 31us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5137\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 8us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2510 - val_acc: 0.5173\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5191\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5176\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5184\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2509 - val_acc: 0.5192\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5181\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5197 - val_loss: 0.2508 - val_acc: 0.5173\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5185\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5178\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2509 - val_acc: 0.5167\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5181\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5179\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 35us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2508 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5160\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5183 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5167\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2510 - val_acc: 0.5160\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2510 - val_acc: 0.5158\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 32us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2509 - val_acc: 0.5183\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2509 - val_acc: 0.5168\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5175\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2508 - acc: 0.5186 - val_loss: 0.2510 - val_acc: 0.5171\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5157\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2509 - val_acc: 0.5161\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 33us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5174\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5190\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5176\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 33us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2510 - val_acc: 0.5157\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5185 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5175\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 33us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5171\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5179\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5170\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5179\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5166\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 33us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5178\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5169\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5178\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2509 - val_acc: 0.5174\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 15s 33us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2509 - val_acc: 0.5174\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 33us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5170\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5175\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5190\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 10us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5168\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5197 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 34us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5185\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2510 - val_acc: 0.5150\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5185\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5195\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 34us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5187 - val_loss: 0.2508 - val_acc: 0.5184\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5176\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5173\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5175\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2509 - val_acc: 0.5164\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 34us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5184\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5177\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2508 - val_acc: 0.5188\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5190\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 16s 35us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5169\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5190\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5197 - val_loss: 0.2509 - val_acc: 0.5179\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5197 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 13s 28us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5189\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5196\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2508 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 36us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5167\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5165\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 5s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 5s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 36us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2508 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2508 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5179\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 5s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5166\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 5s 12us/step - loss: 0.2507 - acc: 0.5198 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2510 - val_acc: 0.5176\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 36us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5180\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 4s 9us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5181\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 5s 11us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2508 - val_acc: 0.5176\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2509 - val_acc: 0.5180\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 5s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5190\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 37us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5194\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5194\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5183\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2509 - val_acc: 0.5166\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5163\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5177\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2511 - val_acc: 0.5136\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 37us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5188 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5186 - val_loss: 0.2507 - val_acc: 0.5182\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5192\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2511 - val_acc: 0.5160\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5196\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2509 - val_acc: 0.5177\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 37us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5174\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5187\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2507 - val_acc: 0.5180\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5183\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5189 - val_loss: 0.2507 - val_acc: 0.5178\n",
      "Epoch 7/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5179\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5190 - val_loss: 0.2509 - val_acc: 0.5161\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "y_true shape (?, ?)\n",
      "y_pred shape (?, 1)\n",
      "Train on 465088 samples, validate on 116271 samples\n",
      "Epoch 1/10\n",
      "465088/465088 [==============================] - 17s 37us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5172\n",
      "Epoch 2/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5192 - val_loss: 0.2508 - val_acc: 0.5193\n",
      "Epoch 3/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5186\n",
      "Epoch 4/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2508 - val_acc: 0.5191\n",
      "Epoch 5/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5193 - val_loss: 0.2507 - val_acc: 0.5193\n",
      "Epoch 6/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5179\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5196 - val_loss: 0.2507 - val_acc: 0.5191\n",
      "Epoch 8/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5191 - val_loss: 0.2508 - val_acc: 0.5180\n",
      "Epoch 9/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5194 - val_loss: 0.2507 - val_acc: 0.5192\n",
      "Epoch 10/10\n",
      "465088/465088 [==============================] - 6s 12us/step - loss: 0.2507 - acc: 0.5195 - val_loss: 0.2507 - val_acc: 0.5195\n",
      "[[0.25143807643393135, 0.2513593836750295, 0.2514939969412501, 0.25133362694940503, 0.2513153439880626, 0.2513274265948281, 0.2513281275142004, 0.25133881621705023, 0.2512343552169359, 0.2512410482652566], [0.2511246618554964, 0.2513301566427336, 0.25110701311144273, 0.25095023405094535, 0.25104288451124374, 0.2510326872774515, 0.25091980882949233, 0.2510033607203011, 0.25086515068535226, 0.25093004631542576], [0.2509704129286358, 0.2508381457852751, 0.2509721485220691, 0.25080204832482195, 0.25080130387141586, 0.2509681251180666, 0.2508560413405203, 0.2508432622991744, 0.25092327195516534, 0.25125816435024484], [0.25102449148372263, 0.25090857117294435, 0.2507856953318985, 0.250810930028724, 0.25086001268459135, 0.2508040086335742, 0.2508780199700302, 0.2508039980991706, 0.25083252750372687, 0.2508620051842912], [0.25079331629126855, 0.2508035769667824, 0.25078655573474484, 0.25086031519209445, 0.2508404430931863, 0.2508094081520145, 0.25075517014087967, 0.2507624685853511, 0.2507981773278728, 0.25080089239323616], [0.2508799886349978, 0.2509399084140018, 0.25088468110704604, 0.25081740451335205, 0.25100843832542064, 0.25081319267888547, 0.251004536270961, 0.2507816912019663, 0.25083253170605657, 0.2508234289983168], [0.25078790298805903, 0.25077359630182877, 0.25094792442004515, 0.25122815542625804, 0.2507962486405301, 0.2508622701394481, 0.2508453601249686, 0.250761036014107, 0.2509310344921633, 0.2509400945683642], [0.25079770826431963, 0.2508309148669488, 0.25090821399311913, 0.2509420211831215, 0.2507642511961766, 0.2507769785787283, 0.2510254761237877, 0.2507391519450892, 0.25081904658053544, 0.2507797519635593], [0.2507874559662954, 0.2507944104061873, 0.2507958166848681, 0.2507887351495582, 0.25075254541624903, 0.25084564029642936, 0.25084157555324205, 0.2507380130724757, 0.2507630547246048, 0.2507606123677542], [0.25078739220955926, 0.2509314771060304, 0.2509289892691816, 0.2507624625121581, 0.25077128783538016, 0.2508825591850754, 0.25073845358658764, 0.250751369045116, 0.25078508160618945, 0.2508109723790824], [0.25076019059149585, 0.25078567356718845, 0.2507939712057038, 0.25077347939504163, 0.25088236770571154, 0.2507934760205513, 0.2509454573195596, 0.25082983378527557, 0.25075397004753786, 0.2507572702791727], [0.2508526395278499, 0.25093549802708276, 0.25090541773731073, 0.2507403730388015, 0.25080110078470225, 0.25076304048769105, 0.2507576713411112, 0.25077804028611095, 0.2507501951000306, 0.2507543927119373], [0.2507397590052548, 0.2507451203705401, 0.2507975666474751, 0.2507756160337528, 0.25103910749679004, 0.2507695445836848, 0.2507899729746686, 0.250772252371418, 0.25102731839744213, 0.25088621280533946], [0.25080643285466164, 0.2508173815752193, 0.2508425382089328, 0.2507857371852567, 0.25082953957964843, 0.2507595655488451, 0.2507425569601937, 0.2507508020238352, 0.2508347201183923, 0.2508375542554026], [0.2507982631389581, 0.2507687262223339, 0.25073292559707183, 0.2507775665665457, 0.2508285978315411, 0.2508182058011206, 0.25085731679307804, 0.25082146070680417, 0.25073151819418127, 0.2509143900710719], [0.25093289004948566, 0.2507471588093033, 0.25090484344865244, 0.25083788470871854, 0.2507678007832131, 0.25076926597524973, 0.2507561217244121, 0.2509963309091464, 0.25095746035503935, 0.2508151601009682], [0.25079997743546123, 0.2507371872371552, 0.250826137795173, 0.2511387371262615, 0.25073873948751935, 0.25082643270234184, 0.25095454929373684, 0.25083021235635583, 0.25075053209047476, 0.2507542651013205], [0.2507776786196997, 0.250778337484248, 0.2508740668970581, 0.2508559773461776, 0.2507868778487624, 0.25092181313903306, 0.2507382657474486, 0.250823611703411, 0.250730897307723, 0.250822041942699], [0.25078860507957246, 0.2507623426613052, 0.25077914013126956, 0.25081349512051493, 0.2508348079051749, 0.25086360122654483, 0.25072721385924845, 0.2508122815274293, 0.2507985019694398, 0.25077634613233907], [0.25077856522591074, 0.25079711116491854, 0.2507457082537798, 0.2507998857818689, 0.25072703553283054, 0.25081725346298867, 0.2508640400648513, 0.25072623153937174, 0.25076499793593715, 0.2507356005351208], [0.25079886534318374, 0.2509961202554198, 0.2507440334291865, 0.25076622929594466, 0.25077638956256415, 0.25084454639194753, 0.25071942048132856, 0.2507534599493054, 0.25077707358316276, 0.25073960440309623], [0.2507974513337029, 0.2507550210162316, 0.25084575713657387, 0.25073748680853836, 0.25074387991740366, 0.250728502098474, 0.25075063064157804, 0.25073528418850916, 0.25071992841111274, 0.2508271590638151], [0.2507296426894418, 0.25079874536032715, 0.25073576727623226, 0.25084683493430393, 0.25074105317259754, 0.25078041635636905, 0.2507240754428104, 0.2507225490067206, 0.2507930832338317, 0.2507640986768561], [0.2507420900617567, 0.25102317079671904, 0.25075932918747235, 0.25074832444405426, 0.25074554508471264, 0.25077931239679774, 0.25095339085100593, 0.2508933321229126, 0.2509317727265316, 0.2508687166749312], [0.25086723081419926, 0.25075400424263405, 0.2507673717062559, 0.2507685177673011, 0.25073026413749233, 0.2508387585164712, 0.2507692956924746, 0.2507389402058569, 0.25077224366686685, 0.2507263197531797], [0.25071965147617636, 0.25075698746968955, 0.2507579970784367, 0.2507265441632242, 0.25074335739980674, 0.25071788578898735, 0.2507576928141317, 0.25074076503016707, 0.2507699967043776, 0.2508950515198829], [0.25083096277991523, 0.25078256833569823, 0.25072545929830087, 0.25077024211735577, 0.2507243933145127, 0.25073789636305327, 0.2508858955516192, 0.2508056819212862, 0.25074694458020025, 0.250782639785812], [0.25079374783707836, 0.25072061255910133, 0.25072769582763194, 0.2507663388287261, 0.25091421648858314, 0.2507541206662622, 0.25075647292460024, 0.2508274534278466, 0.2507630172937532, 0.25077478677146386], [0.25073593488651724, 0.25073305326792333, 0.2507204938150285, 0.250760310016605, 0.25102647198826394, 0.25072042316078136, 0.25075494535456067, 0.2507818508276967, 0.2507978449201339, 0.25101579775147587], [0.25073424931118815, 0.2507270934921716, 0.25077803183223857, 0.2507990386016869, 0.25077968511896304, 0.2508584003876906, 0.25072668512287005, 0.25089824925824733, 0.2507334237975465, 0.2507460847996934], [0.2507388190406065, 0.2509657739101187, 0.2509032616343414, 0.2507649469866305, 0.2508376758381946, 0.25075130724075223, 0.2507647683111078, 0.2508026134972828, 0.2507281708574936, 0.25088561608323806], [0.2507194015479045, 0.25093966112298344, 0.2507466540296644, 0.2508191070776787, 0.250780509431756, 0.25074141519042054, 0.2507385691318148, 0.25073250718780354, 0.2508083378966909, 0.250789031411879], [0.2507520741986014, 0.2507718347680128, 0.2507317579781651, 0.25072015961537214, 0.2507481080272791, 0.2507806989636175, 0.25095679500334483, 0.2507809974576971, 0.2507787838705999, 0.25076458971094245], [0.2507437782520396, 0.25076287534600245, 0.25082422512922825, 0.25073923075664906, 0.2507446021721537, 0.25072398339961505, 0.2508499468274928, 0.2507348421247, 0.25073638385347635, 0.2508568138243241], [0.25072296276638467, 0.25075266091508264, 0.25072951384337344, 0.2507379993958726, 0.25082945915431193, 0.25085136128527336, 0.25079114044234785, 0.2507347546908669, 0.2509214387795099, 0.2507447767148089], [0.2508258990105721, 0.250739688911062, 0.25072900497879835, 0.25080065556305825, 0.2507505684158278, 0.25071923972809407, 0.2507575990377156, 0.2508005549088677, 0.2508995321499154, 0.25072163472972564], [0.2507816448784263, 0.2507975421396524, 0.2507234793120341, 0.25071965352876896, 0.2507316190324079, 0.2509035335613414, 0.25076423497638867, 0.25080285291421955, 0.250784634253007, 0.25082187689456636], [0.2507405541578014, 0.2508245287632479, 0.2508570446346231, 0.2507354974061823, 0.25071997089014264, 0.2507475887841416, 0.25082590136613236, 0.25074938075851116, 0.2507195078028944, 0.2507488171072963], [0.2507770844328373, 0.2508235990638696, 0.2509810338536364, 0.25076539657772334, 0.25073684772480065, 0.25072586794673246, 0.25072476588827, 0.2508086569871842, 0.2507245396452972, 0.25075052809730036], [0.25077982872021964, 0.25082065039383095, 0.2507392002486839, 0.250923704985824, 0.25078071923091916, 0.2509572616311103, 0.25074116314650186, 0.2507163000455814, 0.2507434560183216, 0.25088793756934735], [0.25072391190900306, 0.2507865765185268, 0.2507150008577427, 0.2507221614837425, 0.25075374773417264, 0.2507838972766463, 0.2507242455919228, 0.2508033704838584, 0.2508241006890058, 0.2507591895581157], [0.25084923285667643, 0.25074697159865544, 0.2507227319727463, 0.25072996425263255, 0.25073496151776936, 0.25074239072582244, 0.2509039243592915, 0.25073265264710765, 0.25079073520217354, 0.2507440964382438], [0.2507620506661624, 0.2507864519101599, 0.25079375724906655, 0.2507206455984607, 0.25073465298577363, 0.25072895471257856, 0.2507436814490234, 0.2508208819079785, 0.2507375531625424, 0.25072443783203774], [0.25082787374591325, 0.2507648942984642, 0.2508448398657875, 0.25082423755320643, 0.2507753375024694, 0.2507704467850374, 0.25078551760321355, 0.2507492314398306, 0.25073758038553917, 0.2507368605586309], [0.2509051860521992, 0.2507244272140745, 0.25076097338927006, 0.25085508575202287, 0.2507445660877394, 0.250793473387399, 0.25074994794639854, 0.2507152938894345, 0.25072413752963635, 0.25099971732993526], [0.25079635815588186, 0.2507512354246167, 0.2508675909219423, 0.2507379147471883, 0.25073797244841745, 0.25079480034444757, 0.2508093386911829, 0.25081090500057623, 0.2508658243155978, 0.2507795742828058], [0.25075035785181243, 0.25073646088619095, 0.25077738029658403, 0.2508470114511185, 0.2508544105372209, 0.2508979043483533, 0.2507686355837599, 0.2507551290682653, 0.25071842024227714, 0.25106702674896325], [0.2507611124721572, 0.2507274909936001, 0.2507145494467937, 0.2507974439238127, 0.25073788100064826, 0.2507560842592139, 0.2507987042748969, 0.25106034136326194, 0.25071245400065356, 0.25088049346718183], [0.25078751416426837, 0.2508128965734311, 0.2507709756711054, 0.250741142520099, 0.250741511033014, 0.25073656447957726, 0.25073348536071527, 0.25075281729429233, 0.2508888889706378, 0.25071968475980655], [0.2507813248434021, 0.2507699282972683, 0.2508023841082658, 0.25078611132844764, 0.25072503940674695, 0.2507230153709914, 0.2507299448893636, 0.25077845428440687, 0.2507380267134506, 0.25072652284040603]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(174,176,50)\n",
    "lvals = []\n",
    "for theta in thetas:\n",
    "    model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\n",
    "    model.fit(np.array(X_train), np.argmax(Y_train,axis=1), epochs=10, batch_size=batch_size,validation_data=(np.array(X_val), np.argmax(Y_val,axis=1)),verbose=1)\n",
    "    lvals+=[model.history.history['val_loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvals_plot = [lvals[i][-1] for i in range(len(lvals))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We expect a maximum at 175 but the result doesn't show that quite yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thetas,lvals_plot, label = \"lvals\")\n",
    "plt.vlines(175, ymin = np.min(lvals), ymax = np.max(lvals), label = 'Truth')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
