{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the alternative DCTR fitting method applied on Lund jet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import keras\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global plot settings\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=22) \n",
    "rc('xtick', labelsize=15) \n",
    "rc('ytick', labelsize=15) \n",
    "rc('legend', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes = (100,100, 128)\n",
    "F_sizes = (100,100, 100)\n",
    "\n",
    "dctr = PFN(input_dim=7, \n",
    "           Phi_sizes=Phi_sizes, F_sizes=F_sizes,\n",
    "           summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load model from saved file\n",
    "dctr.model.load_weights('./saved_models/DCTR_ee_dijets_1D_aLund.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddParams2Input(keras.layers.Layer):\n",
    "    \"\"\" Custom layer for tuning with DCTR: \n",
    "    Arguments:\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Usage: \n",
    "    Let X_dim be the input dimension of each particle to a PFN model, and n_MC_params be the number of MC parameters. \n",
    "    Defines a Layer that takes in an array of dimension \n",
    "    (batch_size, padded_multiplicity, X_dim - n_MC_params)\n",
    "    This layer appends each particle by the default_MC_params and makes then trainable or non-trainable based on trainable_MC_params\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_MC_params, default_MC_params, trainable_MC_params):\n",
    "        super(AddParams2Input, self).__init__()\n",
    "        # Definitions\n",
    "        self.n_MC_params = n_MC_params\n",
    "        self.MC_params = default_MC_params\n",
    "        self.trainable_MC_params = trainable_MC_params\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Convert input MC parameters to weights and make then trainable or non-trainable\n",
    "        for i in range(self.n_MC_params):\n",
    "            self.MC_params[i] = self.add_weight(name='MC_param_{}'.format(i), \n",
    "                                                shape=(1, 1),\n",
    "                                                initializer=keras.initializers.Constant(self.MC_params[i]),\n",
    "                                                trainable=self.trainable_MC_params[i])\n",
    "            \n",
    "        self.MC_params = keras.backend.tf.concat(self.MC_params, axis = -1)\n",
    "        super(AddParams2Input, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        # Add MC params to each input particle (but not to the padded rows)\n",
    "        concat_input_and_params = keras.backend.tf.where(keras.backend.abs(input[...,0])>0,\n",
    "                                                         self.MC_params*keras.backend.ones_like(input[...,0:self.n_MC_params]),\n",
    "                                                         keras.backend.zeros_like(input[...,0:self.n_MC_params]))\n",
    "        return keras.backend.concatenate([input, concat_input_and_params], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]+self.n_MC_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_DCTR_fit_model(DCTR_model, \n",
    "                       X_dim, \n",
    "                       n_MC_params, \n",
    "                       default_MC_params,\n",
    "                       trainable_MC_params):\n",
    "    \"\"\" \n",
    "    Get a DCTR model that trains on the input MC parameters\n",
    "    \n",
    "    Arguments:\n",
    "    - DCTR_model : a PFN model that has been trained on a to continuously interpolate over the input MC dimensions\n",
    "    - X_dim : (int) - the dimension of the input expected by DCTR_model\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Returns:\n",
    "    - DCTR_fit_model: a compiled model that gradient descends only on the trainable MC parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do sanity checks on inputs\n",
    "    assert X_dim >=n_MC_params, \"X_dim must be larger than n_MC_params. X_dim includes the dimensionality of the 4-vector + number of MC parameters\"\n",
    "    assert n_MC_params == len(default_MC_params), \"Dimension mismatch between n_MC_params and number of default MC parameters given. len(default_MC_params) must equal n_MC_params\"\n",
    "    assert n_MC_params == len(trainable_MC_params), \"Dimension mismatch between n_MC_params and trainable_MC_params. len(trainable_MC_params) must equal n_MC_params.\"\n",
    "    assert np.any(trainable_MC_params), \"All parameters are set to non-trainable.\"\n",
    "    \n",
    "    # Define input to DCTR_fit_model\n",
    "    non_param_input = keras.layers.Input((None, X_dim - n_MC_params))\n",
    "\n",
    "    # Construct layer that adds trainable and non-trainable parameters to the input\n",
    "    add_params_layer = AddParams2Input(n_MC_params, default_MC_params, trainable_MC_params)\n",
    "    time_dist     = keras.layers.TimeDistributed(add_params_layer, name='tdist')(non_param_input)     \n",
    "\n",
    "    # Set all weights in DCTR_model to non-trainable\n",
    "    for layer in DCTR_model.model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # get the graph and the weights from the DCTR_model\n",
    "    output = DCTR_model.model(inputs = time_dist)\n",
    "\n",
    "    # Define full model\n",
    "    DCTR_fit_model = fitmodel = keras.models.Model(inputs = non_param_input, outputs = output)\n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    DCTR_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return DCTR_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_MC_params(dctr_fit_model, MC_params):\n",
    "    alphaS, aLund, StoUD = MC_params\n",
    "    weights = [np.array([[alphaS]],   dtype=np.float32),\n",
    "               np.array([[aLund]],    dtype=np.float32),\n",
    "               np.array([[StoUD]], dtype=np.float32)]\n",
    "    dctr_fit_model.layers[1].set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_dataset = np.load(data_dir + 'test1D_default.npz')\n",
    "unknown_dataset = np.load(data_dir + 'test1D_aLund.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_default = preprocess_data(default_dataset['jet'][:,:,:4])\n",
    "X_unknown = preprocess_data(unknown_dataset['jet'][:,:,:4])\n",
    "\n",
    "Y_default = np.zeros_like(X_unknown[:,0,0])\n",
    "Y_unknown = np.ones_like(X_unknown[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fit = np.concatenate((X_default, X_unknown), axis = 0)\n",
    "\n",
    "Y_fit = np.concatenate((Y_default, Y_unknown), axis = 0)\n",
    "Y_fit = to_categorical(Y_fit, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fit, _, Y_fit, _ = data_split(X_fit, Y_fit, test=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "tdist (TimeDistributed)      (None, None, 7)           3         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2)                 57130     \n",
      "=================================================================\n",
      "Total params: 57,133\n",
      "Trainable params: 1\n",
      "Non-trainable params: 57,132\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dctr_fit_model = get_DCTR_fit_model(dctr, \n",
    "                       X_dim =7, \n",
    "                       n_MC_params = 3, \n",
    "                       default_MC_params   = [0.1365, 0.68, 0.217], # default params for [alpha_s, aLund, StoUD]\n",
    "                       trainable_MC_params = [False, True, False]) # Only train aLund\n",
    "\n",
    "dctr_fit_model.summary()\n",
    "set_MC_params(dctr_fit_model, [0.68, 0.1365, 0.217])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dctr_fit_model.layers[0].trainable,dctr_fit_model.layers[1].trainable,dctr_fit_model.layers[2].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_weights = keras.callbacks.LambdaCallback(on_epoch_end=lambda batch, logs: print(\"aLund fit = \", \n",
    "                                               dctr_fit_model.get_weights()[0][0][0]))\n",
    "fit_vals = [0.68]\n",
    "append_weights = keras.callbacks.LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "                                               fit_vals.append(dctr_fit_model.get_weights()[0][0][0]))\n",
    "callbacks = [print_weights, append_weights]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 887us/step - loss: 0.6931\n",
      "aLund fit =  0.6816125\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 75s 417us/step - loss: 0.6931\n",
      "aLund fit =  0.6816125\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 156s 866us/step - loss: 0.6931\n",
      "aLund fit =  0.68334705\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 74s 412us/step - loss: 0.6931\n",
      "aLund fit =  0.68334705\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 168s 931us/step - loss: 0.6931\n",
      "aLund fit =  0.6850707\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 427us/step - loss: 0.6931\n",
      "aLund fit =  0.6850707\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 158s 879us/step - loss: 0.6931\n",
      "aLund fit =  0.68675596\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 92s 513us/step - loss: 0.6931\n",
      "aLund fit =  0.68675596\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 204s 1ms/step - loss: 0.6931\n",
      "aLund fit =  0.6884318\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 80s 445us/step - loss: 0.6931\n",
      "aLund fit =  0.6884318\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 890us/step - loss: 0.6931\n",
      "aLund fit =  0.6900476\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 80s 445us/step - loss: 0.6931\n",
      "aLund fit =  0.6900476\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 191s 1ms/step - loss: 0.6931\n",
      "aLund fit =  0.69180214\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 101s 560us/step - loss: 0.6931\n",
      "aLund fit =  0.69180214\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 182s 1ms/step - loss: 0.6930\n",
      "aLund fit =  0.6934119\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 87s 481us/step - loss: 0.6930\n",
      "aLund fit =  0.6934119\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 176s 978us/step - loss: 0.6930\n",
      "aLund fit =  0.69501805\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 74s 412us/step - loss: 0.6930\n",
      "aLund fit =  0.69501805\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 153s 848us/step - loss: 0.6930\n",
      "aLund fit =  0.69668305\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 76s 420us/step - loss: 0.6930\n",
      "aLund fit =  0.69668305\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 155s 859us/step - loss: 0.6930\n",
      "aLund fit =  0.69830906\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 82s 454us/step - loss: 0.6930\n",
      "aLund fit =  0.69830906\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 163s 904us/step - loss: 0.6930\n",
      "aLund fit =  0.69995576\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 79s 438us/step - loss: 0.6930\n",
      "aLund fit =  0.69995576\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 159s 885us/step - loss: 0.6930\n",
      "aLund fit =  0.7015646\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 79s 439us/step - loss: 0.6930\n",
      "aLund fit =  0.7015646\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 158s 878us/step - loss: 0.6930\n",
      "aLund fit =  0.7030521\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 431us/step - loss: 0.6930\n",
      "aLund fit =  0.7030521\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 887us/step - loss: 0.6930\n",
      "aLund fit =  0.70479673\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 429us/step - loss: 0.6930\n",
      "aLund fit =  0.70479673\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 159s 884us/step - loss: 0.6930\n",
      "aLund fit =  0.70628846\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 434us/step - loss: 0.6930\n",
      "aLund fit =  0.70628846\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 157s 873us/step - loss: 0.6930\n",
      "aLund fit =  0.70781946\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 428us/step - loss: 0.6930\n",
      "aLund fit =  0.70781946\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 161s 892us/step - loss: 0.6930\n",
      "aLund fit =  0.70943964\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 82s 457us/step - loss: 0.6930\n",
      "aLund fit =  0.70943964\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 168s 935us/step - loss: 0.6930\n",
      "aLund fit =  0.71109366\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 431us/step - loss: 0.6930\n",
      "aLund fit =  0.71109366\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 166s 922us/step - loss: 0.6930\n",
      "aLund fit =  0.7127471\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 88s 487us/step - loss: 0.6929\n",
      "aLund fit =  0.7127471\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 888us/step - loss: 0.6929\n",
      "aLund fit =  0.7144092\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 427us/step - loss: 0.6929\n",
      "aLund fit =  0.7144092\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 164s 911us/step - loss: 0.6929\n",
      "aLund fit =  0.71581876\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 428us/step - loss: 0.6929\n",
      "aLund fit =  0.71581876\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 201s 1ms/step - loss: 0.6929\n",
      "aLund fit =  0.7173955\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 81s 451us/step - loss: 0.6929\n",
      "aLund fit =  0.7173955\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 165s 916us/step - loss: 0.6929\n",
      "aLund fit =  0.7188552\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 80s 445us/step - loss: 0.6929\n",
      "aLund fit =  0.7188552\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 166s 924us/step - loss: 0.6929\n",
      "aLund fit =  0.72035027\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 82s 453us/step - loss: 0.6929\n",
      "aLund fit =  0.72035027\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 166s 922us/step - loss: 0.6929\n",
      "aLund fit =  0.7220055\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 434us/step - loss: 0.6929\n",
      "aLund fit =  0.7220055\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 887us/step - loss: 0.6929\n",
      "aLund fit =  0.7234908\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 79s 440us/step - loss: 0.6929\n",
      "aLund fit =  0.7234908\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 168s 933us/step - loss: 0.6929\n",
      "aLund fit =  0.72496086\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 81s 448us/step - loss: 0.6929\n",
      "aLund fit =  0.72496086\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 167s 929us/step - loss: 0.6929\n",
      "aLund fit =  0.7264639\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 80s 447us/step - loss: 0.6929\n",
      "aLund fit =  0.7264639\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 171s 950us/step - loss: 0.6929\n",
      "aLund fit =  0.7279833\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 88s 492us/step - loss: 0.6929\n",
      "aLund fit =  0.7279833\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 129s 718us/step - loss: 0.6929\n",
      "aLund fit =  0.7293237\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 303us/step - loss: 0.6929\n",
      "aLund fit =  0.7293237\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 118s 654us/step - loss: 0.6929\n",
      "aLund fit =  0.7309807\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 54s 298us/step - loss: 0.6929\n",
      "aLund fit =  0.7309807\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 108s 600us/step - loss: 0.6929\n",
      "aLund fit =  0.73244363\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 53s 294us/step - loss: 0.6929\n",
      "aLund fit =  0.73244363\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 107s 593us/step - loss: 0.6929\n",
      "aLund fit =  0.7338077\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 52s 287us/step - loss: 0.6929\n",
      "aLund fit =  0.7338077\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 106s 588us/step - loss: 0.6929\n",
      "aLund fit =  0.7349887\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 67s 373us/step - loss: 0.6929\n",
      "aLund fit =  0.7349887\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 156s 868us/step - loss: 0.6929\n",
      "aLund fit =  0.7361095\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 434us/step - loss: 0.6929\n",
      "aLund fit =  0.7361095\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 169s 938us/step - loss: 0.6929\n",
      "aLund fit =  0.73698616\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 428us/step - loss: 0.6929\n",
      "aLund fit =  0.73698616\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 159s 882us/step - loss: 0.6929\n",
      "aLund fit =  0.7384465\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 428us/step - loss: 0.6929\n",
      "aLund fit =  0.7384465\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 157s 871us/step - loss: 0.6929\n",
      "aLund fit =  0.7395953\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 427us/step - loss: 0.6929\n",
      "aLund fit =  0.7395953\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 157s 871us/step - loss: 0.6929\n",
      "aLund fit =  0.7409817\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 428us/step - loss: 0.6929\n",
      "aLund fit =  0.7409817\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 157s 870us/step - loss: 0.6929\n",
      "aLund fit =  0.7424128\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 77s 430us/step - loss: 0.6929\n",
      "aLund fit =  0.7424128\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 159s 881us/step - loss: 0.6929\n",
      "aLund fit =  0.7431949\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 435us/step - loss: 0.6929\n",
      "aLund fit =  0.7431949\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 157s 871us/step - loss: 0.6929\n",
      "aLund fit =  0.74426645\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 78s 434us/step - loss: 0.6929\n",
      "aLund fit =  0.74426645\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 889us/step - loss: 0.6929\n",
      "aLund fit =  0.7449212\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 81s 449us/step - loss: 0.6929\n",
      "aLund fit =  0.7449212\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 161s 897us/step - loss: 0.6929\n",
      "aLund fit =  0.7458664\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 68s 377us/step - loss: 0.6928\n",
      "aLund fit =  0.7458664\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 110s 614us/step - loss: 0.6928\n",
      "aLund fit =  0.74713093\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 349us/step - loss: 0.6928\n",
      "aLund fit =  0.74713093\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 111s 619us/step - loss: 0.6928\n",
      "aLund fit =  0.74821806\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 304us/step - loss: 0.6928\n",
      "aLund fit =  0.74821806\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 112s 624us/step - loss: 0.6928\n",
      "aLund fit =  0.7493156\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 304us/step - loss: 0.6928\n",
      "aLund fit =  0.7493156\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 118s 654us/step - loss: 0.6928\n",
      "aLund fit =  0.75004387\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 73s 403us/step - loss: 0.6928\n",
      "aLund fit =  0.75004387\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 132s 732us/step - loss: 0.6928\n",
      "aLund fit =  0.7509597\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 58s 319us/step - loss: 0.6928\n",
      "aLund fit =  0.7509597\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 120s 668us/step - loss: 0.6928\n",
      "aLund fit =  0.7522895\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 303us/step - loss: 0.6928\n",
      "aLund fit =  0.7522895\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 108s 602us/step - loss: 0.6928\n",
      "aLund fit =  0.75309354\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 92s 510us/step - loss: 0.6928\n",
      "aLund fit =  0.75309354\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 160s 887us/step - loss: 0.6928\n",
      "aLund fit =  0.7539965\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 72s 399us/step - loss: 0.6928\n",
      "aLund fit =  0.7539965\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 117s 650us/step - loss: 0.6928\n",
      "aLund fit =  0.755122\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 307us/step - loss: 0.6928\n",
      "aLund fit =  0.755122\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 113s 625us/step - loss: 0.6928\n",
      "aLund fit =  0.7559113\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 309us/step - loss: 0.6928\n",
      "aLund fit =  0.7559113\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 114s 631us/step - loss: 0.6928\n",
      "aLund fit =  0.75678146\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 314us/step - loss: 0.6928\n",
      "aLund fit =  0.75678146\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 116s 642us/step - loss: 0.6928\n",
      "aLund fit =  0.7577323\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 59s 327us/step - loss: 0.6928\n",
      "aLund fit =  0.7577323\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 118s 654us/step - loss: 0.6928\n",
      "aLund fit =  0.7580134\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 58s 322us/step - loss: 0.6928\n",
      "aLund fit =  0.7580134\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 119s 660us/step - loss: 0.6928\n",
      "aLund fit =  0.7590061\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 59s 327us/step - loss: 0.6928\n",
      "aLund fit =  0.7590061\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 120s 669us/step - loss: 0.6928\n",
      "aLund fit =  0.7598917\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 345us/step - loss: 0.6928\n",
      "aLund fit =  0.7598917\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 688us/step - loss: 0.6928\n",
      "aLund fit =  0.76074904\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 59s 329us/step - loss: 0.6928\n",
      "aLund fit =  0.76074904\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 121s 672us/step - loss: 0.6928\n",
      "aLund fit =  0.7615534\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 61s 341us/step - loss: 0.6928\n",
      "aLund fit =  0.7615534\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 122s 677us/step - loss: 0.6928\n",
      "aLund fit =  0.76189923\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 343us/step - loss: 0.6928\n",
      "aLund fit =  0.76189923\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 690us/step - loss: 0.6928\n",
      "aLund fit =  0.76276934\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 61s 338us/step - loss: 0.6928\n",
      "aLund fit =  0.76276934\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 690us/step - loss: 0.6928\n",
      "aLund fit =  0.7633781\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 344us/step - loss: 0.6928\n",
      "aLund fit =  0.7633781\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 691us/step - loss: 0.6928\n",
      "aLund fit =  0.764147\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 61s 339us/step - loss: 0.6928\n",
      "aLund fit =  0.764147\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 700us/step - loss: 0.6928\n",
      "aLund fit =  0.76505697\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.76505697\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 125s 696us/step - loss: 0.6928\n",
      "aLund fit =  0.76509136\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 342us/step - loss: 0.6928\n",
      "aLund fit =  0.76509136\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 125s 696us/step - loss: 0.6928\n",
      "aLund fit =  0.7654514\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 61s 341us/step - loss: 0.6928\n",
      "aLund fit =  0.7654514\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 706us/step - loss: 0.6928\n",
      "aLund fit =  0.76632106\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.76632106\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 125s 695us/step - loss: 0.6928\n",
      "aLund fit =  0.7667285\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 354us/step - loss: 0.6928\n",
      "aLund fit =  0.7667285\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 710us/step - loss: 0.6928\n",
      "aLund fit =  0.767563\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.767563\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 702us/step - loss: 0.6928\n",
      "aLund fit =  0.7680575\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 67s 370us/step - loss: 0.6928\n",
      "aLund fit =  0.7680575\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 707us/step - loss: 0.6928\n",
      "aLund fit =  0.7683307\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.7683307\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 701us/step - loss: 0.6928\n",
      "aLund fit =  0.7688857\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 348us/step - loss: 0.6928\n",
      "aLund fit =  0.7688857\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 125s 697us/step - loss: 0.6928\n",
      "aLund fit =  0.76943547\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.76943547\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 713us/step - loss: 0.6928\n",
      "aLund fit =  0.77011484\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.77011484\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 705us/step - loss: 0.6928\n",
      "aLund fit =  0.7705467\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 349us/step - loss: 0.6928\n",
      "aLund fit =  0.7705467\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 699us/step - loss: 0.6928\n",
      "aLund fit =  0.77058417\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 347us/step - loss: 0.6928\n",
      "aLund fit =  0.77058417\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 703us/step - loss: 0.6928\n",
      "aLund fit =  0.771255\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 62s 345us/step - loss: 0.6928\n",
      "aLund fit =  0.771255\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 699us/step - loss: 0.6928\n",
      "aLund fit =  0.77135956\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 354us/step - loss: 0.6928\n",
      "aLund fit =  0.77135956\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 710us/step - loss: 0.6928\n",
      "aLund fit =  0.77192163\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 355us/step - loss: 0.6928\n",
      "aLund fit =  0.77192163\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 709us/step - loss: 0.6928\n",
      "aLund fit =  0.7721926\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.7721926\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 703us/step - loss: 0.6928\n",
      "aLund fit =  0.77293813\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 350us/step - loss: 0.6928\n",
      "aLund fit =  0.77293813\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 703us/step - loss: 0.6928\n",
      "aLund fit =  0.7730292\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 355us/step - loss: 0.6928\n",
      "aLund fit =  0.7730292\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 712us/step - loss: 0.6928\n",
      "aLund fit =  0.7731997\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 352us/step - loss: 0.6928\n",
      "aLund fit =  0.7731997\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 707us/step - loss: 0.6928\n",
      "aLund fit =  0.77314764\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.77314764\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 702us/step - loss: 0.6928\n",
      "aLund fit =  0.7733266\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 350us/step - loss: 0.6928\n",
      "aLund fit =  0.7733266\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 711us/step - loss: 0.6928\n",
      "aLund fit =  0.7735405\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.7735405\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 705us/step - loss: 0.6928\n",
      "aLund fit =  0.77402693\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.77402693\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 132s 734us/step - loss: 0.6928\n",
      "aLund fit =  0.77430534\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 65s 363us/step - loss: 0.6928\n",
      "aLund fit =  0.77430534\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 712us/step - loss: 0.6928\n",
      "aLund fit =  0.7741675\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 68s 375us/step - loss: 0.6928\n",
      "aLund fit =  0.7741675\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 708us/step - loss: 0.6928\n",
      "aLund fit =  0.77370816\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 353us/step - loss: 0.6928\n",
      "aLund fit =  0.77370816\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 713us/step - loss: 0.6928\n",
      "aLund fit =  0.7743437\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.7743437\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 711us/step - loss: 0.6928\n",
      "aLund fit =  0.7745649\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 65s 363us/step - loss: 0.6928\n",
      "aLund fit =  0.7745649\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 707us/step - loss: 0.6928\n",
      "aLund fit =  0.7749854\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 354us/step - loss: 0.6928\n",
      "aLund fit =  0.7749854\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 708us/step - loss: 0.6928\n",
      "aLund fit =  0.77479887\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.77479887\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 705us/step - loss: 0.6928\n",
      "aLund fit =  0.7744099\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 352us/step - loss: 0.6928\n",
      "aLund fit =  0.7744099\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 127s 704us/step - loss: 0.6928\n",
      "aLund fit =  0.77459747\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 351us/step - loss: 0.6928\n",
      "aLund fit =  0.77459747\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 128s 709us/step - loss: 0.6928\n",
      "aLund fit =  0.7746042\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 358us/step - loss: 0.6928\n",
      "aLund fit =  0.7746042\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    dctr_fit_model.layers[0].trainable = False\n",
    "    dctr_fit_model.layers[1].trainable = True\n",
    "    dctr_fit_model.layers[2].trainable = False\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    dctr_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    dctr_fit_model.fit(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)],\n",
    "           epochs=1, \n",
    "           batch_size=10000,\n",
    "           callbacks = callbacks)\n",
    "    \n",
    "    dctr_fit_model.layers[0].trainable = False\n",
    "    dctr_fit_model.layers[1].trainable = False\n",
    "    dctr_fit_model.layers[2].trainable = True\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    dctr_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    dctr_fit_model.fit(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)],\n",
    "           epochs=1, \n",
    "           batch_size=10000,\n",
    "           callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 187s 1ms/step - loss: 0.6928\n",
      "aLund fit =  0.7748053\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 356us/step - loss: 0.6928\n",
      "aLund fit =  0.7748053\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 111s 616us/step - loss: 0.6928\n",
      "aLund fit =  0.7748424\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 310us/step - loss: 0.6928\n",
      "aLund fit =  0.7748424\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 114s 633us/step - loss: 0.6928\n",
      "aLund fit =  0.77477103\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 58s 323us/step - loss: 0.6928\n",
      "aLund fit =  0.77477103\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 136s 754us/step - loss: 0.6928\n",
      "aLund fit =  0.774617\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 68s 378us/step - loss: 0.6928\n",
      "aLund fit =  0.774617\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 111s 616us/step - loss: 0.6928\n",
      "aLund fit =  0.7741826\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 75s 419us/step - loss: 0.6928\n",
      "aLund fit =  0.7741826\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 690us/step - loss: 0.6928\n",
      "aLund fit =  0.7736157\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 307us/step - loss: 0.6928\n",
      "aLund fit =  0.7736157\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 112s 623us/step - loss: 0.6928\n",
      "aLund fit =  0.7741639\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 310us/step - loss: 0.6928\n",
      "aLund fit =  0.7741639\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 112s 623us/step - loss: 0.6928\n",
      "aLund fit =  0.7743515\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 314us/step - loss: 0.6928\n",
      "aLund fit =  0.7743515\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 125s 696us/step - loss: 0.6928\n",
      "aLund fit =  0.7743987\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 80s 443us/step - loss: 0.6928\n",
      "aLund fit =  0.7743987\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 126s 698us/step - loss: 0.6928\n",
      "aLund fit =  0.7745927\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 55s 304us/step - loss: 0.6928\n",
      "aLund fit =  0.7745927\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 110s 612us/step - loss: 0.6928\n",
      "aLund fit =  0.7747601\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 56s 309us/step - loss: 0.6928\n",
      "aLund fit =  0.7747601\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 111s 616us/step - loss: 0.6928\n",
      "aLund fit =  0.77482027\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 65s 361us/step - loss: 0.6928\n",
      "aLund fit =  0.77482027\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 121s 670us/step - loss: 0.6928\n",
      "aLund fit =  0.7748107\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 73s 405us/step - loss: 0.6928\n",
      "aLund fit =  0.7748107\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 133s 737us/step - loss: 0.6928\n",
      "aLund fit =  0.77449423\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 65s 361us/step - loss: 0.6928\n",
      "aLund fit =  0.77449423\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 116s 644us/step - loss: 0.6928\n",
      "aLund fit =  0.7742807\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 54s 301us/step - loss: 0.6928\n",
      "aLund fit =  0.7742807\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 106s 588us/step - loss: 0.6928\n",
      "aLund fit =  0.7746754\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 54s 300us/step - loss: 0.6928\n",
      "aLund fit =  0.7746754\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 109s 605us/step - loss: 0.6928\n",
      "aLund fit =  0.7748769\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 58s 325us/step - loss: 0.6928\n",
      "aLund fit =  0.7748769\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 108s 600us/step - loss: 0.6928\n",
      "aLund fit =  0.77546406\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 54s 303us/step - loss: 0.6928\n",
      "aLund fit =  0.77546406\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 109s 608us/step - loss: 0.6928\n",
      "aLund fit =  0.7757443\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 54s 301us/step - loss: 0.6928\n",
      "aLund fit =  0.7757443\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 688us/step - loss: 0.6928\n",
      "aLund fit =  0.7762485\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 75s 418us/step - loss: 0.6928\n",
      "aLund fit =  0.7762485\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 124s 687us/step - loss: 0.6928\n",
      "aLund fit =  0.77660906\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 63s 348us/step - loss: 0.6928\n",
      "aLund fit =  0.77660906\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 156s 866us/step - loss: 0.6928\n",
      "aLund fit =  0.77704173\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 72s 400us/step - loss: 0.6928\n",
      "aLund fit =  0.77704173\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 158s 880us/step - loss: 0.6928\n",
      "aLund fit =  0.7768723\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 79s 438us/step - loss: 0.6928\n",
      "aLund fit =  0.7768723\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 159s 883us/step - loss: 0.6928\n",
      "aLund fit =  0.77676696\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 64s 353us/step - loss: 0.6928\n",
      "aLund fit =  0.77676696\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 113s 628us/step - loss: 0.6928\n",
      "aLund fit =  0.7763462\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 57s 316us/step - loss: 0.6928\n",
      "aLund fit =  0.7763462\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 120s 667us/step - loss: 0.6928\n",
      "aLund fit =  0.776394\n",
      "Epoch 1/1\n",
      "180000/180000 [==============================] - 57s 319us/step - loss: 0.6928\n",
      "aLund fit =  0.776394\n",
      "Epoch 1/1\n",
      " 90000/180000 [==============>...............] - ETA: 1:10 - loss: 0.6929"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    dctr_fit_model.layers[0].trainable = False\n",
    "    dctr_fit_model.layers[1].trainable = True\n",
    "    dctr_fit_model.layers[2].trainable = False\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    dctr_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    dctr_fit_model.fit(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)],\n",
    "           epochs=1, \n",
    "           batch_size=10000,\n",
    "           callbacks = callbacks)\n",
    "    \n",
    "    dctr_fit_model.layers[0].trainable = False\n",
    "    dctr_fit_model.layers[1].trainable = False\n",
    "    dctr_fit_model.layers[2].trainable = True\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    dctr_fit_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    dctr_fit_model.fit(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)],\n",
    "           epochs=1, \n",
    "           batch_size=10000,\n",
    "           callbacks = callbacks)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
