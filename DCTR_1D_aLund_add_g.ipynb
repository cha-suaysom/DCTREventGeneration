{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the alternative DCTR fitting method applied on Lund jet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/anaconda3/lib/python3.5/site-packages/cntk/cntk_py_init.py:98: UserWarning: \n",
      "\n",
      "################################################ Missing optional dependency (GPU-Specific) ################################################\n",
      "   CNTK may crash if the component that depends on those dependencies is loaded.\n",
      "   Visit https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-Linux-Python#optional-gpu-specific-packages for more information.\n",
      "############################################################################################################################################\n",
      "If you intend to use CNTK without GPU support, you can ignore the (likely) GPU-specific warning!\n",
      "############################################################################################################################################\n",
      "\n",
      "  warnings.warn(WARNING_MSG_GPU_ONLY % ('GPU-Specific', 'https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-Linux-Python#optional-gpu-specific-packages'))\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import keras\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "import cntk as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize pT and center (y, phi)\n",
    "def normalize(x):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    for x in X:\n",
    "        normalize(x)\n",
    "    \n",
    "    # Remap PIDs to unique values in range [0,1]\n",
    "    remap_pids(X, pid_i=3)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 7)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    800         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 57,130\n",
      "Trainable params: 57,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network architecture parameters\n",
    "Phi_sizes = (100,100, 128)\n",
    "F_sizes = (100,100, 100)\n",
    "\n",
    "dctr = PFN(input_dim=7, \n",
    "           Phi_sizes=Phi_sizes, F_sizes=F_sizes,\n",
    "           summary=True)\n",
    "\n",
    "#load model from saved file\n",
    "dctr.model.load_weights('./saved_models/DCTR_ee_dijets_1D_aLund.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset_0 = np.load('test1D_default.npz')\n",
    "test_dataset_1 = np.load('test1D_aLund.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<energyflow.archs.efn.PFN at 0x7f2ac2234940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_default = preprocess_data(test_dataset_0['jet'][:,:,:4])\n",
    "X_unknown = preprocess_data(test_dataset_1['jet'][:,:,:4])\n",
    "\n",
    "Y_default = np.zeros_like(X_unknown[:,0,0])\n",
    "Y_unknown = np.ones_like(X_unknown[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fit = np.concatenate((X_default, X_unknown), axis = 0)\n",
    "\n",
    "Y_fit = np.concatenate((Y_default, Y_unknown), axis = 0)\n",
    "Y_fit = to_categorical(Y_fit, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_fit, _, Y_fit, _ = data_split(X_fit, Y_fit, test=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddParams2Input(keras.layers.Layer):\n",
    "    \"\"\" Custom layer for tuning with DCTR: \n",
    "    Arguments:\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Usage: \n",
    "    Let X_dim be the input dimension of each particle to a PFN model, and n_MC_params be the number of MC parameters. \n",
    "    Defines a Layer that takes in an array of dimension \n",
    "    (batch_size, padded_multiplicity, X_dim - n_MC_params)\n",
    "    This layer appends each particle by the default_MC_params and makes then trainable or non-trainable based on trainable_MC_params\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_MC_params, default_MC_params, trainable_MC_params):\n",
    "        super(AddParams2Input, self).__init__()\n",
    "        # Definitions\n",
    "        self.n_MC_params = n_MC_params\n",
    "        self.MC_params = default_MC_params\n",
    "        self.trainable_MC_params = trainable_MC_params\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Convert input MC parameters to weights and make then trainable or non-trainable\n",
    "        for i in range(self.n_MC_params):\n",
    "            self.MC_params[i] = self.add_weight(name='MC_param_{}'.format(i), \n",
    "                                                shape=(1, 1),\n",
    "                                                initializer=keras.initializers.Constant(self.MC_params[i]),\n",
    "                                                trainable=self.trainable_MC_params[i])\n",
    "            \n",
    "        self.MC_params = keras.backend.tf.concat(self.MC_params, axis = -1)\n",
    "        super(AddParams2Input, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        # Add MC params to each input particle (but not to the padded rows)\n",
    "        concat_input_and_params = keras.backend.tf.where(keras.backend.abs(input[...,0])>0,\n",
    "                                                         self.MC_params*keras.backend.ones_like(input[...,0:self.n_MC_params]),\n",
    "                                                         keras.backend.zeros_like(input[...,0:self.n_MC_params]))\n",
    "        return keras.backend.concatenate([input, concat_input_and_params], -1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]+self.n_MC_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import nn\n",
    "from tensorflow.python.ops import variables as variables_module\n",
    "\n",
    "def _backtrack_identity(tensor):\n",
    "    while tensor.op.type == 'Identity':\n",
    "        tensor = tensor.op.inputs[0]\n",
    "    return tensor\n",
    "\n",
    "def my_loss_wrapper():\n",
    "    def my_loss(y_true,y_pred):\n",
    "        target = y_true\n",
    "        output = y_pred\n",
    "        axis = -1\n",
    "        from_logits = False\n",
    "        target.shape.assert_is_compatible_with(output.shape)\n",
    "        if from_logits:\n",
    "            return nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=target, logits=output, axis=axis)\n",
    "\n",
    "        if not isinstance(output, (ops.EagerTensor, variables_module.Variable)):\n",
    "            output = _backtrack_identity(output)\n",
    "            if output.op.type == 'Softmax':\n",
    "                # When softmax activation function is used for output operation, we\n",
    "                # use logits from the softmax function directly to compute loss in order\n",
    "                # to prevent collapsing zero when training.\n",
    "                # See b/117284466\n",
    "                assert len(output.op.inputs) == 1\n",
    "                output = output.op.inputs[0]\n",
    "                return nn.softmax_cross_entropy_with_logits_v2(\n",
    "                  labels=target, logits=output)\n",
    "\n",
    "        # scale preds so that the class probas of each sample sum to 1\n",
    "        output = output / math_ops.reduce_sum(output, axis, True)\n",
    "        # Compute cross entropy from probabilities.\n",
    "        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "        output = clip_ops.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "        return -math_ops.reduce_sum(target * math_ops.log(output), axis)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_DCTR_fit_model(DCTR_model, \n",
    "                       X_dim, \n",
    "                       n_MC_params, \n",
    "                       default_MC_params,\n",
    "                       trainable_MC_params):\n",
    "    \"\"\" \n",
    "    Get a DCTR model that trains on the input MC parameters\n",
    "    \n",
    "    Arguments:\n",
    "    - DCTR_model : a PFN model that has been trained on a to continuously interpolate over the input MC dimensions\n",
    "    - X_dim : (int) - the dimension of the input expected by DCTR_model\n",
    "    - n_MC_params : (int) - the number of n_MC_params that are in X_dim\n",
    "    - default_MC_params : (list of floats) - default values for each of the MC parameters\n",
    "    - trainable_MC_params : (list of booleans) - True for parameters that you want to fit, false for parameters that should be fixed at default value\n",
    "\n",
    "    Returns:\n",
    "    - DCTR_fit_model: a compiled model that gradient descends only on the trainable MC parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do sanity checks on inputs\n",
    "    assert X_dim >=n_MC_params, \"X_dim must be larger than n_MC_params. X_dim includes the dimensionality of the 4-vector + number of MC parameters\"\n",
    "    assert n_MC_params == len(default_MC_params), \"Dimension mismatch between n_MC_params and number of default MC parameters given. len(default_MC_params) must equal n_MC_params\"\n",
    "    assert n_MC_params == len(trainable_MC_params), \"Dimension mismatch between n_MC_params and trainable_MC_params. len(trainable_MC_params) must equal n_MC_params.\"\n",
    "    assert np.any(trainable_MC_params), \"All parameters are set to non-trainable.\"\n",
    "    \n",
    "    # Define input to DCTR_fit_model\n",
    "    non_param_input = keras.layers.Input((None, X_dim - n_MC_params))\n",
    "\n",
    "    # Construct layer that adds trainable and non-trainable parameters to the input\n",
    "    add_params_layer = AddParams2Input(n_MC_params, default_MC_params, trainable_MC_params)\n",
    "    time_dist     = keras.layers.TimeDistributed(add_params_layer, name='tdist')(non_param_input)     \n",
    "\n",
    "    # Set all weights in DCTR_model to non-trainable\n",
    "    for layer in DCTR_model.model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # get the graph and the weights from the DCTR_model\n",
    "    output = DCTR_model.model(inputs = time_dist)\n",
    "\n",
    "    # Define full model\n",
    "    DCTR_fit_model = fitmodel = keras.models.Model(inputs = non_param_input, outputs = output)\n",
    "    optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    # Compile with loss function\n",
    "    DCTR_fit_model.compile(optimizer=optimizer, loss=my_loss_wrapper())\n",
    "    \n",
    "    \n",
    "    return DCTR_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_MC_params(dctr_fit_model, MC_params):\n",
    "    alphaS, aLund, StoUD = MC_params\n",
    "    weights = [np.array([[alphaS]],   dtype=np.float32),\n",
    "               np.array([[aLund]],    dtype=np.float32),\n",
    "               np.array([[StoUD]], dtype=np.float32)]\n",
    "    dctr_fit_model.layers[1].set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(X, Y, dctr_fit_model, MC_params, batch_size = 1000):\n",
    "    set_MC_params(dctr_fit_model, MC_params)\n",
    "    return dctr_fit_model.evaluate(x=X, y = Y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dctr_fit_model = get_DCTR_fit_model(dctr, \n",
    "                       X_dim =7, \n",
    "                       n_MC_params = 3, \n",
    "                       default_MC_params   = [0.1365, 0.68, 0.217], # default params for [alpha_s, aLund, StoUD]\n",
    "                       trainable_MC_params = [False, True, False]) # Only train aLund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weight to use in loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thetas = np.linspace(0.6,0.9, 20)\n",
    "train_result_list = []\n",
    "for i in range(len(thetas)):\n",
    "    weight_value = dctr.predict(test_dataset_0['jet'][:100000,:,:])\n",
    "    weight = weight_value[:,0]/weight_value[:,1]\n",
    "    weight = tf.convert_to_tensor(weight.astype(np.float32))\n",
    "    train_result_list.append(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myinputs = Input(shape=(1,))\n",
    "\n",
    "x = Dense(128, activation='relu')(myinputs)\n",
    "x2 = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x2)\n",
    "          \n",
    "model = Model(inputs=myinputs, outputs=predictions)\n",
    "\n",
    "def my_loss_wrapper(weight,val=0.0):\n",
    "            \n",
    "    theta0 = val #target value \n",
    "    def my_loss(y_true,y_pred):\n",
    "        t_loss = y_true*(y_true - y_pred)**2+(weight**2)*(1.-y_true)*(y_true - y_pred)**2\n",
    "        return K.mean(t_loss)\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_3 to have 2 dimensions, but got array with shape (180000, 51, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-ced50f627392>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_loss_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_result_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mlvals\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_3 to have 2 dimensions, but got array with shape (180000, 51, 4)"
     ]
    }
   ],
   "source": [
    "lvals = []\n",
    "for i in range(len(thetas)):\n",
    "    theta = thetas[i]\n",
    "    model.compile(optimizer='adam', loss=my_loss_wrapper(train_result_list[i],theta),metrics=['accuracy'])\n",
    "    model.fit(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)], epochs=1, batch_size=int(len(X_fit)/10),validation_data=(X_fit[-int(len(X_fit)/10):], Y_fit[-int(len(X_fit)/10):]),verbose=1)\n",
    "    lvals+=[model.history.history['val_loss']]\n",
    "    print\n",
    "    pass\n",
    "print(lvals) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000/180000 [==============================] - 44s 243us/step\n",
      "180000/180000 [==============================] - 44s 244us/step\n",
      "180000/180000 [==============================] - 46s 257us/step\n",
      "180000/180000 [==============================] - 62s 343us/step\n",
      "180000/180000 [==============================] - 45s 250us/step\n",
      "180000/180000 [==============================] - 45s 250us/step\n",
      "180000/180000 [==============================] - 52s 286us/step\n",
      "180000/180000 [==============================] - 45s 248us/step\n",
      "180000/180000 [==============================] - 45s 248us/step\n",
      "180000/180000 [==============================] - 45s 251us/step\n",
      "180000/180000 [==============================] - 45s 251us/step\n",
      "180000/180000 [==============================] - 49s 272us/step\n",
      "180000/180000 [==============================] - 52s 291us/step\n",
      "180000/180000 [==============================] - 74s 414us/step\n",
      "180000/180000 [==============================] - 55s 307us/step\n",
      "180000/180000 [==============================] - 58s 322us/step\n",
      "180000/180000 [==============================] - 55s 307us/step\n",
      "180000/180000 [==============================] - 59s 330us/step\n",
      "180000/180000 [==============================] - 78s 432us/step\n",
      "180000/180000 [==============================] - 64s 354us/step\n"
     ]
    }
   ],
   "source": [
    "aLund_loss = np.array([(aLund, get_loss(X_fit[:int(len(X_fit)/10)], Y_fit[:int(len(X_fit)/10)], dctr_fit_model, [aLund, 0.1365, 0.217])) for aLund in thetas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6       , 0.69359449],\n",
       "       [0.61578947, 0.69350439],\n",
       "       [0.63157895, 0.69341753],\n",
       "       [0.64736842, 0.69333671],\n",
       "       [0.66315789, 0.69325262],\n",
       "       [0.67894737, 0.69316377],\n",
       "       [0.69473684, 0.693074  ],\n",
       "       [0.71052632, 0.69299457],\n",
       "       [0.72631579, 0.69293157],\n",
       "       [0.74210526, 0.69288282],\n",
       "       [0.75789474, 0.69285285],\n",
       "       [0.77368421, 0.69283769],\n",
       "       [0.78947368, 0.69283435],\n",
       "       [0.80526316, 0.69283885],\n",
       "       [0.82105263, 0.69284742],\n",
       "       [0.83684211, 0.6928584 ],\n",
       "       [0.85263158, 0.69286957],\n",
       "       [0.86842105, 0.69288147],\n",
       "       [0.88421053, 0.69289347],\n",
       "       [0.9       , 0.69290492]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aLund_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.6       , 0.61578947, 0.63157895, 0.64736842, 0.66315789,\n",
       "        0.67894737, 0.69473684, 0.71052632, 0.72631579, 0.74210526,\n",
       "        0.75789474, 0.77368421, 0.78947368, 0.80526316, 0.82105263,\n",
       "        0.83684211, 0.85263158, 0.86842105, 0.88421053, 0.9       ]),\n",
       " array([0.69359449, 0.69350439, 0.69341753, 0.69333671, 0.69325262,\n",
       "        0.69316377, 0.693074  , 0.69299457, 0.69293157, 0.69288282,\n",
       "        0.69285285, 0.69283769, 0.69283435, 0.69283885, 0.69284742,\n",
       "        0.6928584 , 0.69286957, 0.69288147, 0.69289347, 0.69290492]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aLund_loss[:,0], aLund_loss[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYaDR7SwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.cla()\n",
    "plt.plot(aLund_loss[:,0],aLund_loss[:,1])\n",
    "plt.savefig(\"aLund.png\")\n",
    "display(Image(filename=\"aLund.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
